{"cells":[{"cell_type":"code","execution_count":null,"id":"d35be239","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d35be239","executionInfo":{"status":"ok","timestamp":1674034430274,"user_tz":-60,"elapsed":30601,"user":{"displayName":"Marie Mortensen","userId":"14481540874930151406"}},"outputId":"dff67b0e-68d9-4400-b1a6-914ae4262071"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive/')\n","\n","\n","import os\n","os.chdir(\"drive/My Drive/Advanced NLP/Exam\")\n","\n","import pickle\n","import random\n","import time\n","from collections import Counter, defaultdict\n","\n","import matplotlib.pyplot as plt\n","import matplotlib.ticker as ticker\n","import torch\n","import torch.nn as nn\n","from torch import optim\n","\n","plt.switch_backend('agg')\n","import numpy as np\n","from tqdm import tqdm\n","\n","from models import EncoderGRU, AttnDecoderGRU, EncoderLSTM, DecoderLSTM, AttnDecoderLSTM\n","from utils import Lang, tensorsFromPair, timeSince, showPlot\n"]},{"cell_type":"code","execution_count":null,"id":"2ab36ae6","metadata":{"id":"2ab36ae6"},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","dataset_path = '../SCAN-master'\n","task_name = 'add_prim'  # or 'length'\n","primitive = 'turn_left'\n","\n","train_file_name = '{}_split/tasks_{}_{}.txt'.format(task_name, 'train', 'addprim'+'_'+primitive)\n","test_file_name = '{}_split/tasks_{}_{}.txt'.format(task_name, 'test', 'addprim'+'_'+primitive)\n","train_file_path = os.path.join(dataset_path, train_file_name)\n","test_file_path = os.path.join(dataset_path, test_file_name)\n","\n","# train_file_path, test_file_path\n","\n","SOS_token = 0\n","EOS_token = 1\n","\n","command_le = Lang('command')\n","action_le = Lang('action')\n","\n","\n","def dataloader(path):\n","    with open(path, 'r') as f:\n","        dataset = f.readlines()\n","\n","    def preprocess_data(line):\n","        line = line.strip().split()\n","        split_index = line.index('OUT:')\n","        inp = line[1: split_index]\n","        outp = line[split_index + 1:]\n","        command_le.addSentence(inp)\n","        action_le.addSentence(outp)\n","        return [inp, outp]\n","\n","    pairs = list(map(preprocess_data, dataset))\n","    input_commands, output_actions = np.transpose(pairs).tolist()\n","    return input_commands, output_actions, pairs\n","\n","\n","commands_train, actions_train, pairs_train = dataloader(train_file_path)\n","commands_test, actions_test, pairs_test = dataloader(test_file_path)\n","\n","MAX_LENGTH = max([len(action) for action in actions_test]) + 1\n","\n","teacher_forcing_ratio = 0.5\n","\n","\n","def train(input_tensor, target_tensor, encoder, decoder,\n","          encoder_optimizer, decoder_optimizer, criterion,\n","          model='lstm', attention=False):\n","    encoder_hidden = encoder.initHidden()\n","\n","    encoder_optimizer.zero_grad()\n","    decoder_optimizer.zero_grad()\n","\n","    input_length = input_tensor.size(0)\n","    target_length = target_tensor.size(0)\n","\n","    encoder_hiddens = torch.zeros(input_length, encoder.hidden_size, device=device)\n","\n","    loss = 0\n","    gold_pred = 0\n","\n","    for ei in range(input_length):\n","        encoder_output, encoder_hidden = encoder(\n","            input_tensor[ei], encoder_hidden)\n","        if attention:\n","            if model == \"lstm\":\n","                encoder_hiddens[ei] = encoder_hidden[0][0,0]\n","            elif model == \"gru\":\n","                encoder_hiddens[ei] = encoder_hidden[0,0]\n","\n","    decoder_input = torch.tensor([[SOS_token]], device=device)\n","\n","    decoder_hidden = encoder_hidden\n","    \n","    preds = []\n","    \n","    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n","    \n","    if use_teacher_forcing:\n","        for di in range(target_length):\n","            if attention:\n","                decoder_output, decoder_hidden, decoder_attention = decoder(\n","                    decoder_input, decoder_hidden, encoder_hiddens)\n","            else:\n","                decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n","            topv, topi = decoder_output.topk(1)\n","            pred = topi.squeeze()\n","            preds.append(topi.squeeze().item())\n","            \n","            loss += criterion(decoder_output, target_tensor[di])\n","            decoder_input = target_tensor[di]\n","    \n","\n","    else:\n","        for di in range(target_length):\n","            if attention:\n","                decoder_output, decoder_hidden, decoder_attention = decoder(\n","                    decoder_input, decoder_hidden, encoder_hiddens)\n","            else:\n","                decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n","            topv, topi = decoder_output.topk(1)\n","            pred = topi.squeeze()\n","            preds.append(topi.squeeze().item())\n","            decoder_input = topi.squeeze().detach()\n","\n","            loss += criterion(decoder_output, target_tensor[di])\n","            if decoder_input.item() == EOS_token:\n","                target_length = di + 1\n","                break\n","                \n","    correct = torch.equal(torch.Tensor(preds).to(device), target_tensor.squeeze())\n","\n","    loss.backward()\n","\n","    torch.nn.utils.clip_grad_norm_(encoder.parameters(), max_norm=5.0)\n","    torch.nn.utils.clip_grad_norm_(decoder.parameters(), max_norm=5.0)\n","    \n","    encoder_optimizer.step()\n","    decoder_optimizer.step()\n","\n","    return loss.item() / target_length, correct\n","\n","\n","def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100,\n","               learning_rate=0.001, model='gru', attention=False):\n","    start = time.time()\n","\n","    accuracy = 0 \n","    plot_losses = []\n","    plot_accs = []\n","    print_loss_total = 0\n","    plot_loss_total = 0\n","    print_pred_total = 0\n","    print_label_total = 0\n","    plot_pred_total = 0\n","    plot_label_total = 0\n","\n","    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n","    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n","    training_pairs = [tensorsFromPair(random.choice(pairs_train), command_le, action_le)\n","                      for i in range(n_iters)]\n","    criterion = nn.NLLLoss()\n","\n","    for iter in range(1, n_iters + 1):\n","        training_pair = training_pairs[iter - 1]\n","        input_tensor = training_pair[0]\n","        target_tensor = training_pair[1]\n","        # target_length = target_tensor.size(0)\n","\n","        loss, correct = train(input_tensor, target_tensor, encoder, decoder, \n","                              encoder_optimizer, decoder_optimizer, criterion, \n","                              model, attention=attention)\n","        print_pred_total += int(correct)\n","        plot_pred_total += int(correct)\n","        print_loss_total += loss\n","        plot_loss_total += loss\n","\n","        if iter % print_every == 0:            \n","            print_acc_avg = print_pred_total / print_every\n","            accuracy = print_acc_avg\n","            print_loss_avg = print_loss_total / print_every\n","            print_pred_total = 0\n","            print_label_total = 0\n","            print_loss_total = 0\n","            print('%s (%d %d%%) loss: %.4f acc: %.4f' % (timeSince(start, iter / n_iters),\n","                                                         iter, iter / n_iters * 100, print_loss_avg, print_acc_avg))\n","\n","        if iter % plot_every == 0:\n","            plot_acc_avg = plot_pred_total / plot_every\n","            plot_loss_avg = plot_loss_total / plot_every\n","            plot_losses.append(plot_loss_avg)\n","            plot_accs.append(plot_acc_avg)\n","            plot_loss_total = 0\n","            plot_pred_total = 0\n","            plot_label_total = 0\n","\n","    showPlot(plot_losses, plot_accs)\n","    return accuracy\n","\n","\n","def evaluate(encoder, decoder, pair, model='gru', attention=False, max_length=MAX_LENGTH):\n","    with torch.no_grad():\n","        input_tensor, target_tensor = tensorsFromPair(pair, command_le, action_le)\n","        input_length = input_tensor.size()[0]\n","        encoder_hidden = encoder.initHidden()\n","\n","        encoder_hiddens = torch.zeros(input_length, encoder.hidden_size, device=device)\n","\n","        for ei in range(input_length):\n","            encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n","            \n","            if attention:\n","                if model == 'lstm':\n","                    encoder_hiddens[ei] += encoder_hidden[0][0,0]\n","                elif model == 'gru':\n","                    encoder_hiddens[ei] += encoder_hidden[0,0]\n","\n","\n","        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n","\n","        decoder_hidden = encoder_hidden\n","\n","        decoded_words = []\n","        decoder_attentions = torch.zeros(max_length, input_length)\n","\n","        for di in range(max_length):\n","            if attention:\n","                decoder_output, decoder_hidden, decoder_attention = decoder(\n","                    decoder_input, decoder_hidden, encoder_hiddens)\n","                decoder_attentions[di] = decoder_attention.squeeze().data\n","            else:\n","                decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n","            topv, topi = decoder_output.data.topk(1)\n","            if topi.item() == EOS_token:\n","                decoded_words.append('<EOS>')\n","                break\n","            else:\n","                decoded_words.append(action_le.index2word[topi.item()])\n","\n","            decoder_input = topi.squeeze().detach()\n","\n","        return decoded_words, decoder_attentions[:di+1]\n","\n","\n","def evaluate_model(encoder, decoder, test_pairs, model='gru', attention=False):\n","    command_cnt = Counter([len(test_pair[0]) for test_pair in test_pairs])\n","    action_cnt = Counter([len(test_pair[1]) for test_pair in test_pairs])\n","    command_correct_cnt = defaultdict(int)\n","    action_correct_cnt = defaultdict(int)\n","    correct = 0\n","\n","    for pair in tqdm(test_pairs):\n","        preds, attentions = evaluate(encoder, decoder, pair, model=model, attention=attention)\n","        preds = preds[:-1]\n","        target_output = pair[1]\n","        if preds == target_output:\n","            command_correct_cnt[len(pair[0])] += 1\n","            action_correct_cnt[len(pair[1])] += 1\n","            correct += 1\n","            \n","    command_correct_cnt = dict(command_correct_cnt)\n","    action_correct_cnt = dict(action_correct_cnt)\n","    command_cnt = dict(command_cnt)\n","    action_cnt = dict(action_cnt)\n","\n","    command_acc = {}\n","    for command_length, cnt in command_cnt.items():\n","        command_acc[command_length] = command_correct_cnt.get(\n","            command_length, 0) / cnt\n","\n","    action_acc = {}\n","    for action_length, cnt in action_cnt.items():\n","        action_acc[action_length] = action_correct_cnt.get(\n","            action_length, 0) / cnt\n","            \n","    return command_acc, action_acc, correct / len(test_pairs)\n","\n","\n","def evaluateRandomly(encoder, decoder, model='gru', n=10):\n","    for i in range(n):\n","        pair = random.choice(pairs_test)\n","        print('>', pair[0])\n","        print('=', pair[1])\n","        output_words, attentions = evaluate(encoder, decoder, pair, model=model)\n","        output_sentence = output_words\n","        print('<', output_sentence)\n","        print('')\n","        \n","\n","def showAttention(input_sentence, output_words, attentions):\n","    # Set up figure with colorbar\n","    fig = plt.figure(figsize=(16,8))\n","    ax = fig.add_subplot(111)\n","    cax = ax.matshow(attentions.cpu().numpy(), cmap='bone')\n","    fig.colorbar(cax)\n","\n","    # Set up axes\n","    ax.set_xticklabels([''] + input_sentence +\n","                       ['<EOS>'], rotation=90)\n","    ax.set_yticklabels([''] + output_words)\n","\n","    # Show label at every tick\n","    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n","    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n","\n","    plt.show()\n","\n","\n","def evaluateAndShowAttention(encoder, decoder, pair, model='gru'):\n","    output_words, attentions = evaluate(\n","        encoder, decoder, pair, model=model)\n","    print('input =', pair[0])\n","    print('output =', output_words)\n","    showAttention(pair[0], output_words, attentions)\n","    \n","\n","\n","def evaluateAndShowAttentionExample(encoder, decoder, model='gru'):\n","    for i in range(len(pairs_test)):\n","        preds, attentions = evaluate(encoder, decoder, pairs_test[i], model=model)\n","        preds = preds[:-1]\n","        target_output = pairs_test[i][1]\n","        if preds == target_output:\n","            evaluateAndShowAttention(encoder, decoder, pairs_test[i])\n","            break\n","        \n","        \n","def main_run(hidden_size, num_iter, num_runs, model, dropout=0.5, num_layers=1, attention=True, experiment=\"3a\"):\n","\n","    input_size = command_le.n_words\n","    output_size = action_le.n_words\n","\n","    best_encoder = None\n","    best_decoder = None\n","    best_acc = 0\n","\n","    command_accs, action_accs, overall_accs, train_accs = [], [], [], []\n","\n","    for i in range(num_runs):\n","        if model == \"lstm\":\n","            encoder = EncoderLSTM(input_size, hidden_size, num_layers=num_layers, dropout=dropout).to(device)\n","        elif model == \"gru\":\n","            encoder = EncoderGRU(input_size, hidden_size, num_layers=num_layers, dropout=dropout).to(device)\n","\n","        if attention:\n","            if model == \"lstm\":\n","                decoder = AttnDecoderLSTM(hidden_size, output_size, dropout=dropout).to(device)\n","            elif model == \"gru\":\n","                decoder = AttnDecoderGRU(hidden_size, output_size, dropout=0.5).to(device)\n","\n","        else:\n","            if model == \"lstm\":\n","                decoder = DecoderLSTM(hidden_size, output_size, num_layers=num_layers, dropout=dropout).to(device)\n","\n","        accuracy_train = trainIters(encoder, decoder, num_iter, print_every=1000, model=model, attention=attention)\n","        acc_command, acc_action, acc_overall = evaluate_model(encoder, decoder, pairs_test, model=model)\n","            \n","\n","        if acc_overall > best_acc:\n","            best_encoder = encoder\n","            best_decoder = decoder\n","            best_acc = acc_overall\n","\n","        command_accs.append(acc_command)\n","        action_accs.append(acc_action)\n","        overall_accs.append(acc_overall)\n","        train_accs.append(accuracy_train)\n","    \n","    # Save results          \n","    torch.save(best_encoder.state_dict(), f\"encoder_{experiment}_{model}_{attention}.pt\")\n","    torch.save(best_decoder.state_dict(), f\"decoder{experiment}_{model}_{attention}.pt\")\n","\n","    with open(f'train_results_{model}_{attention}.pickle', 'wb') as f:\n","        pickle.dump([command_accs, action_accs,overall_accs, train_accs], f)\n","    \n","    return command_accs, action_accs, overall_accs, train_accs\n","\n","\n","def calculate_mean_std(acc_dict):\n","    mean = []\n","    error = []\n","    keys = sorted(acc_dict[0])\n","    num_runs = len(acc_dict)\n","    \n","    for key in keys:\n","        t = []\n","        for d in acc_dict:\n","            t.append(d[key])\n","        mean.append(np.mean(t))\n","        error.append(np.std(t) / np.sqrt(num_runs))\n","    return mean, error, keys"]},{"cell_type":"code","execution_count":null,"id":"602028f5","metadata":{"id":"602028f5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1674036087500,"user_tz":-60,"elapsed":340401,"user":{"displayName":"Marie Mortensen","userId":"14481540874930151406"}},"outputId":"5b3cc6af-ee3d-4d43-9493-dac48a0a49ec"},"outputs":[{"output_type":"stream","name":"stdout","text":["0m 32s (- 4m 56s) (1000 10%) loss: 1.0930 acc: 0.0980\n","1m 6s (- 4m 24s) (2000 20%) loss: 0.8344 acc: 0.1140\n","1m 39s (- 3m 51s) (3000 30%) loss: 0.6458 acc: 0.1500\n","2m 11s (- 3m 17s) (4000 40%) loss: 0.4686 acc: 0.2890\n","2m 44s (- 2m 44s) (5000 50%) loss: 0.4111 acc: 0.3510\n","3m 16s (- 2m 11s) (6000 60%) loss: 0.3080 acc: 0.4510\n","3m 49s (- 1m 38s) (7000 70%) loss: 0.3233 acc: 0.4400\n","4m 21s (- 1m 5s) (8000 80%) loss: 0.2974 acc: 0.4940\n","4m 55s (- 0m 32s) (9000 90%) loss: 0.2884 acc: 0.5040\n","5m 29s (- 0m 0s) (10000 100%) loss: 0.2338 acc: 0.5830\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1208/1208 [00:11<00:00, 109.71it/s]\n"]},{"output_type":"execute_result","data":{"text/plain":["([{7: 0.3008474576271186,\n","   5: 0.5294117647058824,\n","   8: 0.259375,\n","   6: 0.3716216216216216,\n","   4: 0.8125,\n","   3: 0.0}],\n"," [{25: 0.0625,\n","   3: 0.6,\n","   8: 0.7916666666666666,\n","   6: 0.35294117647058826,\n","   9: 0.017857142857142856,\n","   26: 0.25,\n","   11: 0.4027777777777778,\n","   5: 0.3719512195121951,\n","   19: 0.0,\n","   10: 0.3888888888888889,\n","   7: 0.15833333333333333,\n","   2: 0.6521739130434783,\n","   27: 0.21875,\n","   4: 0.5579710144927537,\n","   13: 0.0,\n","   12: 0.0,\n","   17: 0.0625,\n","   18: 0.25,\n","   14: 0.0,\n","   15: 0.0}],\n"," [0.33278145695364236],\n"," [0.583])"]},"metadata":{},"execution_count":9}],"source":["# top-performing model: Gru with Attention\n","main_run(hidden_size=100, num_layers = 1, dropout=0.1, num_iter=10000, model='gru', num_runs=1, attention=True, experiment=\"3a1\")"]},{"cell_type":"code","execution_count":null,"id":"dc8ffbfb","metadata":{"id":"dc8ffbfb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1674036928360,"user_tz":-60,"elapsed":226202,"user":{"displayName":"Marie Mortensen","userId":"14481540874930151406"}},"outputId":"8ea2fb3a-470b-4107-a59c-5e3ae15514e1"},"outputs":[{"output_type":"stream","name":"stdout","text":["0m 22s (- 3m 20s) (1000 10%) loss: 1.1823 acc: 0.1010\n","0m 45s (- 3m 0s) (2000 20%) loss: 0.7575 acc: 0.1140\n","1m 5s (- 2m 33s) (3000 30%) loss: 0.5888 acc: 0.1650\n","1m 27s (- 2m 10s) (4000 40%) loss: 0.4850 acc: 0.2200\n","1m 48s (- 1m 48s) (5000 50%) loss: 0.4210 acc: 0.2380\n","2m 10s (- 1m 27s) (6000 60%) loss: 0.3641 acc: 0.3050\n","2m 33s (- 1m 5s) (7000 70%) loss: 0.3281 acc: 0.3800\n","2m 54s (- 0m 43s) (8000 80%) loss: 0.2709 acc: 0.4180\n","3m 15s (- 0m 21s) (9000 90%) loss: 0.2538 acc: 0.4650\n","3m 37s (- 0m 0s) (10000 100%) loss: 0.2364 acc: 0.4940\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1208/1208 [00:06<00:00, 174.35it/s]\n"]},{"output_type":"execute_result","data":{"text/plain":["([{7: 0.125,\n","   5: 0.30392156862745096,\n","   8: 0.1375,\n","   6: 0.2702702702702703,\n","   4: 0.25,\n","   3: 0.0}],\n"," [{25: 0.0,\n","   3: 0.4117647058823529,\n","   8: 0.5138888888888888,\n","   6: 0.13725490196078433,\n","   9: 0.125,\n","   26: 0.0,\n","   11: 0.2638888888888889,\n","   5: 0.23170731707317074,\n","   19: 0.0,\n","   10: 0.1111111111111111,\n","   7: 0.16666666666666666,\n","   2: 0.2608695652173913,\n","   27: 0.0,\n","   4: 0.17391304347826086,\n","   13: 0.0,\n","   12: 0.0,\n","   17: 0.03125,\n","   18: 0.0,\n","   14: 0.25,\n","   15: 0.0}],\n"," [0.1804635761589404],\n"," [0.494])"]},"metadata":{},"execution_count":13}],"source":["# overall best model: LSTM\n","main_run(hidden_size=200, num_layers=2, dropout=0.5, num_iter=10000, num_runs=1, model='lstm', experiment=\"3a2\", attention=False)"]},{"cell_type":"code","source":[],"metadata":{"id":"QMW9XrtCTki0"},"id":"QMW9XrtCTki0","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.12"},"colab":{"provenance":[]},"accelerator":"GPU","gpuClass":"standard"},"nbformat":4,"nbformat_minor":5}