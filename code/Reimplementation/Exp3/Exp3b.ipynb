{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":389},"executionInfo":{"elapsed":1697585,"status":"error","timestamp":1673879932014,"user":{"displayName":"Marie Mortensen","userId":"14481540874930151406"},"user_tz":-60},"id":"d35be239","outputId":"d0f04ce9-1765-4135-a1d9-9877ebb65e59"},"outputs":[{"output_type":"error","ename":"MessageError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-d3bc4179bfa8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    102\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    122\u001b[0m       'TBE_EPHEM_CREDS_ADDR'] if ephemeral else _os.environ['TBE_CREDS_ADDR']\n\u001b[1;32m    123\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    125\u001b[0m         'request_auth', request={'authType': 'dfs_ephemeral'}, timeout_sec=None)\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    169\u001b[0m   request_id = send_request(\n\u001b[1;32m    170\u001b[0m       request_type, request, parent=parent, expect_reply=True)\n\u001b[0;32m--> 171\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    100\u001b[0m         reply.get('colab_msg_id') == message_id):\n\u001b[1;32m    101\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive/')\n","\n","\n","import os\n","os.chdir(\"drive/My Drive/Advanced NLP/Exam\")\n","\n","import pickle\n","import random\n","import time\n","from collections import Counter, defaultdict\n","\n","import matplotlib.pyplot as plt\n","import matplotlib.ticker as ticker\n","import torch\n","import torch.nn as nn\n","from torch import optim\n","\n","plt.switch_backend('agg')\n","import numpy as np\n","from tqdm import tqdm\n","\n","from models import EncoderGRU, AttnDecoderGRU, EncoderLSTM, DecoderLSTM, AttnDecoderLSTM\n","from utils import Lang, tensorsFromPair, timeSince, showPlot\n"],"id":"d35be239"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1673600797709,"user":{"displayName":"Marie Mortensen","userId":"14481540874930151406"},"user_tz":-60},"id":"jutG5_LRpp6I","outputId":"ab2bf9f5-326b-4440-a7f6-25c8a323f087"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/drive/My Drive/Advanced NLP/Exam'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":4}],"source":["os.getcwd()"],"id":"jutG5_LRpp6I"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2145,"status":"ok","timestamp":1673600799846,"user":{"displayName":"Marie Mortensen","userId":"14481540874930151406"},"user_tz":-60},"id":"2ab36ae6","outputId":"ef08ceae-61bb-493d-d260-942d382cbfee"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:43: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","  result = getattr(asarray(obj), method)(*args, **kwds)\n"]}],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","dataset_path = '../SCAN-master'\n","task_name = 'add_prim'  # or 'length'\n","primitive = 'jump'\n","\n","train_file_name = '{}_split/tasks_{}_{}.txt'.format(task_name, 'train', 'addprim'+'_'+primitive)\n","test_file_name = '{}_split/tasks_{}_{}.txt'.format(task_name, 'test', 'addprim'+'_'+primitive)\n","train_file_path = os.path.join(dataset_path, train_file_name)\n","test_file_path = os.path.join(dataset_path, test_file_name)\n","\n","# train_file_path, test_file_path\n","\n","SOS_token = 0\n","EOS_token = 1\n","\n","command_le = Lang('command')\n","action_le = Lang('action')\n","\n","\n","def dataloader(path):\n","    with open(path, 'r') as f:\n","        dataset = f.readlines()\n","\n","    def preprocess_data(line):\n","        line = line.strip().split()\n","        split_index = line.index('OUT:')\n","        inp = line[1: split_index]\n","        outp = line[split_index + 1:]\n","        command_le.addSentence(inp)\n","        action_le.addSentence(outp)\n","        return [inp, outp]\n","\n","    pairs = list(map(preprocess_data, dataset))\n","    input_commands, output_actions = np.transpose(pairs).tolist()\n","    return input_commands, output_actions, pairs\n","\n","\n","commands_train, actions_train, pairs_train = dataloader(train_file_path)\n","commands_test, actions_test, pairs_test = dataloader(test_file_path)\n","\n","MAX_LENGTH = max([len(action) for action in actions_test]) + 1\n","\n","teacher_forcing_ratio = 0.5\n","\n","\n","def train(input_tensor, target_tensor, encoder, decoder,\n","          encoder_optimizer, decoder_optimizer, criterion,\n","          model='lstm', attention=True):\n","    encoder_hidden = encoder.initHidden()\n","\n","    encoder_optimizer.zero_grad()\n","    decoder_optimizer.zero_grad()\n","\n","    input_length = input_tensor.size(0)\n","    target_length = target_tensor.size(0)\n","\n","    encoder_hiddens = torch.zeros(input_length, encoder.hidden_size, device=device)\n","\n","    loss = 0\n","    gold_pred = 0\n","\n","    for ei in range(input_length):\n","        encoder_output, encoder_hidden = encoder(\n","            input_tensor[ei], encoder_hidden)\n","        if attention:\n","            if model == \"lstm\":\n","                encoder_hiddens[ei] = encoder_hidden[0][0,0]\n","            elif model == \"gru\":\n","                encoder_hiddens[ei] = encoder_hidden[0,0]\n","\n","    decoder_input = torch.tensor([[SOS_token]], device=device)\n","\n","    decoder_hidden = encoder_hidden\n","    \n","    preds = []\n","    \n","    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n","    \n","    if use_teacher_forcing:\n","        for di in range(target_length):\n","            if attention:\n","                decoder_output, decoder_hidden, decoder_attention = decoder(\n","                    decoder_input, decoder_hidden, encoder_hiddens)\n","            else:\n","                decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n","            topv, topi = decoder_output.topk(1)\n","            pred = topi.squeeze()\n","            preds.append(topi.squeeze().item())\n","            \n","            loss += criterion(decoder_output, target_tensor[di])\n","            decoder_input = target_tensor[di]\n","    \n","\n","    else:\n","        for di in range(target_length):\n","            if attention:\n","                decoder_output, decoder_hidden, decoder_attention = decoder(\n","                    decoder_input, decoder_hidden, encoder_hiddens)\n","            else:\n","                decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n","            topv, topi = decoder_output.topk(1)\n","            pred = topi.squeeze()\n","            preds.append(topi.squeeze().item())\n","            decoder_input = topi.squeeze().detach()\n","\n","            loss += criterion(decoder_output, target_tensor[di])\n","            if decoder_input.item() == EOS_token:\n","                target_length = di + 1\n","                break\n","                \n","    correct = torch.equal(torch.Tensor(preds).to(device), target_tensor.squeeze())\n","\n","    loss.backward()\n","\n","    torch.nn.utils.clip_grad_norm_(encoder.parameters(), max_norm=5.0)\n","    torch.nn.utils.clip_grad_norm_(decoder.parameters(), max_norm=5.0)\n","    \n","    encoder_optimizer.step()\n","    decoder_optimizer.step()\n","\n","    return loss.item() / target_length, correct\n","\n","\n","def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100,\n","               learning_rate=0.001, model='gru', attention=True):\n","    start = time.time()\n","\n","    accuracy = 0 \n","    plot_losses = []\n","    plot_accs = []\n","    print_loss_total = 0\n","    plot_loss_total = 0\n","    print_pred_total = 0\n","    print_label_total = 0\n","    plot_pred_total = 0\n","    plot_label_total = 0\n","\n","    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n","    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n","    training_pairs = [tensorsFromPair(random.choice(pairs_train), command_le, action_le)\n","                      for i in range(n_iters)]\n","    criterion = nn.NLLLoss()\n","\n","    for iter in range(1, n_iters + 1):\n","        training_pair = training_pairs[iter - 1]\n","        input_tensor = training_pair[0]\n","        target_tensor = training_pair[1]\n","        # target_length = target_tensor.size(0)\n","\n","        loss, correct = train(input_tensor, target_tensor, encoder, decoder, \n","                              encoder_optimizer, decoder_optimizer, criterion, \n","                              model, attention=attention)\n","        print_pred_total += int(correct)\n","        plot_pred_total += int(correct)\n","        print_loss_total += loss\n","        plot_loss_total += loss\n","\n","        if iter % print_every == 0:            \n","            print_acc_avg = print_pred_total / print_every\n","            accuracy = print_acc_avg\n","            print_loss_avg = print_loss_total / print_every\n","            print_pred_total = 0\n","            print_label_total = 0\n","            print_loss_total = 0\n","            print('%s (%d %d%%) loss: %.4f acc: %.4f' % (timeSince(start, iter / n_iters),\n","                                                         iter, iter / n_iters * 100, print_loss_avg, print_acc_avg))\n","\n","        if iter % plot_every == 0:\n","            plot_acc_avg = plot_pred_total / plot_every\n","            plot_loss_avg = plot_loss_total / plot_every\n","            plot_losses.append(plot_loss_avg)\n","            plot_accs.append(plot_acc_avg)\n","            plot_loss_total = 0\n","            plot_pred_total = 0\n","            plot_label_total = 0\n","\n","    showPlot(plot_losses, plot_accs)\n","    return accuracy\n","\n","\n","def evaluate(encoder, decoder, pair, model='gru', attention=True, max_length=MAX_LENGTH):\n","    with torch.no_grad():\n","        input_tensor, target_tensor = tensorsFromPair(pair, command_le, action_le)\n","        input_length = input_tensor.size()[0]\n","        encoder_hidden = encoder.initHidden()\n","\n","        encoder_hiddens = torch.zeros(input_length, encoder.hidden_size, device=device)\n","\n","        for ei in range(input_length):\n","            encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n","            \n","            if attention:\n","                if model == 'lstm':\n","                    encoder_hiddens[ei] += encoder_hidden[0][0,0]\n","                elif model == 'gru':\n","                    encoder_hiddens[ei] += encoder_hidden[0,0]\n","\n","\n","        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n","\n","        decoder_hidden = encoder_hidden\n","\n","        decoded_words = []\n","        decoder_attentions = torch.zeros(max_length, input_length)\n","\n","        for di in range(max_length):\n","            if attention:\n","                decoder_output, decoder_hidden, decoder_attention = decoder(\n","                    decoder_input, decoder_hidden, encoder_hiddens)\n","                decoder_attentions[di] = decoder_attention.squeeze().data\n","            else:\n","                decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n","            topv, topi = decoder_output.data.topk(1)\n","            if topi.item() == EOS_token:\n","                decoded_words.append('<EOS>')\n","                break\n","            else:\n","                decoded_words.append(action_le.index2word[topi.item()])\n","\n","            decoder_input = topi.squeeze().detach()\n","\n","        return decoded_words, decoder_attentions[:di+1]\n","\n","\n","def evaluate_model(encoder, decoder, test_pairs, model='gru', attention=True):\n","    command_cnt = Counter([len(test_pair[0]) for test_pair in test_pairs])\n","    action_cnt = Counter([len(test_pair[1]) for test_pair in test_pairs])\n","    command_correct_cnt = defaultdict(int)\n","    action_correct_cnt = defaultdict(int)\n","    correct = 0\n","\n","    for pair in tqdm(test_pairs):\n","        preds, attentions = evaluate(encoder, decoder, pair, model=model, attention=attention)\n","        preds = preds[:-1]\n","        target_output = pair[1]\n","        if preds == target_output:\n","            command_correct_cnt[len(pair[0])] += 1\n","            action_correct_cnt[len(pair[1])] += 1\n","            correct += 1\n","            \n","    command_correct_cnt = dict(command_correct_cnt)\n","    action_correct_cnt = dict(action_correct_cnt)\n","    command_cnt = dict(command_cnt)\n","    action_cnt = dict(action_cnt)\n","\n","    command_acc = {}\n","    for command_length, cnt in command_cnt.items():\n","        command_acc[command_length] = command_correct_cnt.get(\n","            command_length, 0) / cnt\n","\n","    action_acc = {}\n","    for action_length, cnt in action_cnt.items():\n","        action_acc[action_length] = action_correct_cnt.get(\n","            action_length, 0) / cnt\n","            \n","    return command_acc, action_acc, correct / len(test_pairs)\n","\n","\n","def evaluateRandomly(encoder, decoder, model='gru', n=10):\n","    for i in range(n):\n","        pair = random.choice(pairs_test)\n","        print('>', pair[0])\n","        print('=', pair[1])\n","        output_words, attentions = evaluate(encoder, decoder, pair, model=model)\n","        output_sentence = output_words\n","        print('<', output_sentence)\n","        print('')\n","        \n","\n","def showAttention(input_sentence, output_words, attentions):\n","    # Set up figure with colorbar\n","    fig = plt.figure(figsize=(16,8))\n","    ax = fig.add_subplot(111)\n","    cax = ax.matshow(attentions.cpu().numpy(), cmap='bone')\n","    fig.colorbar(cax)\n","\n","    # Set up axes\n","    ax.set_xticklabels([''] + input_sentence +\n","                       ['<EOS>'], rotation=90)\n","    ax.set_yticklabels([''] + output_words)\n","\n","    # Show label at every tick\n","    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n","    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n","\n","    plt.show()\n","\n","\n","def evaluateAndShowAttention(encoder, decoder, pair, model='gru'):\n","    output_words, attentions = evaluate(\n","        encoder, decoder, pair, model=model)\n","    print('input =', pair[0])\n","    print('output =', output_words)\n","    showAttention(pair[0], output_words, attentions)\n","    \n","\n","\n","def evaluateAndShowAttentionExample(encoder, decoder, model='gru'):\n","    for i in range(len(pairs_test)):\n","        preds, attentions = evaluate(encoder, decoder, pairs_test[i], model=model)\n","        preds = preds[:-1]\n","        target_output = pairs_test[i][1]\n","        if preds == target_output:\n","            evaluateAndShowAttention(encoder, decoder, pairs_test[i])\n","            break\n","        \n","        \n","def main_run(hidden_size, num_iter, num_runs, model, dropout=0.5, num_layers=1, attention=True, experiment=\"3b1\"):\n","\n","    input_size = command_le.n_words\n","    output_size = action_le.n_words\n","\n","    best_encoder = None\n","    best_decoder = None\n","    best_acc = 0\n","\n","    command_accs, action_accs, overall_accs, train_accs = [], [], [], []\n","\n","    for i in range(num_runs):\n","        if model == \"lstm\":\n","            encoder = EncoderLSTM(input_size, hidden_size, num_layers=num_layers, dropout=dropout).to(device)\n","        elif model == \"gru\":\n","            encoder = EncoderGRU(input_size, hidden_size, num_layers=num_layers, dropout=dropout).to(device)\n","\n","        if attention:\n","            if model == \"lstm\":\n","                decoder = AttnDecoderLSTM(hidden_size, output_size, dropout=dropout).to(device)\n","            elif model == \"gru\":\n","                decoder = AttnDecoderGRU(hidden_size, output_size, dropout=0.5).to(device)\n","\n","        else:\n","            if model == \"lstm\":\n","                decoder = DecoderLSTM(hidden_size, output_size, num_layers=num_layers, dropout=dropout).to(device)\n","\n","        accuracy_train = trainIters(encoder, decoder, num_iter, print_every=1000, model=model, attention=attention)\n","        acc_command, acc_action, acc_overall = evaluate_model(encoder, decoder, pairs_test, model=model, attention=attention)\n","            \n","\n","        if acc_overall > best_acc:\n","            best_encoder = encoder\n","            best_decoder = decoder\n","            best_acc = acc_overall\n","\n","        command_accs.append(acc_command)\n","        action_accs.append(acc_action)\n","        overall_accs.append(acc_overall)\n","        train_accs.append(accuracy_train)\n","        \n","    # Save results          \n","    torch.save(best_encoder.state_dict(), f\"encoder_{experiment}_{model}_{attention}.pt\")\n","    torch.save(best_decoder.state_dict(), f\"decoder{experiment}_{model}_{attention}.pt\")\n","\n","    with open(f'train_results_{model}_{attention}.pickle', 'wb') as f:\n","        pickle.dump([command_accs, action_accs,overall_accs, train_accs], f)\n","   \n","    return command_accs, action_accs, overall_accs, train_accs\n","\n","\n","def calculate_mean_std(acc_dict):\n","    mean = []\n","    error = []\n","    keys = sorted(acc_dict[0])\n","    num_runs = len(acc_dict)\n","    \n","    for key in keys:\n","        t = []\n","        for d in acc_dict:\n","            t.append(d[key])\n","        mean.append(np.mean(t))\n","        error.append(np.std(t) / np.sqrt(num_runs))\n","    return mean, error, keys"],"id":"2ab36ae6"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":353},"executionInfo":{"elapsed":47550,"status":"error","timestamp":1673599898184,"user":{"displayName":"Marie Mortensen","userId":"14481540874930151406"},"user_tz":-60},"id":"602028f5","outputId":"b52f52ee-9f7b-4b00-bb18-8b65870eddb2"},"outputs":[{"name":"stdout","output_type":"stream","text":["0m 33s (- 27m 33s) (1000 2%) loss: 0.9811 acc: 0.1010\n"]},{"ename":"KeyboardInterrupt","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-2c631e4d1b12>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# top-performing model: LSTM with Attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmain_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_layers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'lstm'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_runs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-2-7b3bc73d898c>\u001b[0m in \u001b[0;36mmain_run\u001b[0;34m(hidden_size, num_iter, num_runs, model, dropout, num_layers, attention, experiment)\u001b[0m\n\u001b[1;32m    334\u001b[0m                 \u001b[0mdecoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecoderLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m         \u001b[0maccuracy_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainIters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m         \u001b[0macc_command\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_action\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_overall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpairs_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-2-7b3bc73d898c>\u001b[0m in \u001b[0;36mtrainIters\u001b[0;34m(encoder, decoder, n_iters, print_every, plot_every, learning_rate, model, attention)\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0;31m# target_length = target_tensor.size(0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m         loss, correct = train(input_tensor, target_tensor, encoder, decoder, \n\u001b[0m\u001b[1;32m    152\u001b[0m                               \u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m                               model, attention=attention)\n","\u001b[0;32m<ipython-input-2-7b3bc73d898c>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, model, attention)\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mattention\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m                 decoder_output, decoder_hidden, decoder_attention = decoder(\n\u001b[0m\u001b[1;32m     84\u001b[0m                     decoder_input, decoder_hidden, encoder_hiddens)\n\u001b[1;32m     85\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/My Drive/Advanced NLP/Exam/models.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hidden, encoder_hiddens)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mcat_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    772\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 774\u001b[0;31m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0m\u001b[1;32m    775\u001b[0m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[1;32m    776\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# top-performing model: LSTM with Attention\n","main_run(hidden_size=100, num_layers = 1, dropout=0.1, num_iter=50000, model='lstm', num_runs=1, attention=True)"],"id":"602028f5"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dc8ffbfb","executionInfo":{"status":"ok","timestamp":1673617718924,"user_tz":-60,"elapsed":15933449,"user":{"displayName":"Marie Mortensen","userId":"14481540874930151406"}},"outputId":"103238bd-451c-4d4b-f110-a91e7b5e78df"},"outputs":[{"output_type":"stream","name":"stdout","text":["0m 24s (- 30m 44s) (1000 1%) loss: 1.0924 acc: 0.0900\n","0m 45s (- 27m 33s) (2000 2%) loss: 0.6981 acc: 0.1300\n","1m 5s (- 26m 7s) (3000 4%) loss: 0.5245 acc: 0.1860\n","1m 24s (- 25m 6s) (4000 5%) loss: 0.4675 acc: 0.2250\n","1m 46s (- 24m 44s) (5000 6%) loss: 0.4126 acc: 0.2810\n","2m 6s (- 24m 10s) (6000 8%) loss: 0.3674 acc: 0.3090\n","2m 26s (- 23m 42s) (7000 9%) loss: 0.3210 acc: 0.3640\n","2m 46s (- 23m 15s) (8000 10%) loss: 0.2681 acc: 0.4510\n","3m 6s (- 22m 47s) (9000 12%) loss: 0.2338 acc: 0.5420\n","3m 26s (- 22m 24s) (10000 13%) loss: 0.2233 acc: 0.5520\n","3m 46s (- 21m 59s) (11000 14%) loss: 0.1736 acc: 0.6220\n","4m 6s (- 21m 35s) (12000 16%) loss: 0.1292 acc: 0.6790\n","4m 27s (- 21m 15s) (13000 17%) loss: 0.1070 acc: 0.6670\n","4m 48s (- 20m 57s) (14000 18%) loss: 0.1206 acc: 0.7150\n","5m 8s (- 20m 35s) (15000 20%) loss: 0.0849 acc: 0.7520\n","5m 29s (- 20m 15s) (16000 21%) loss: 0.0812 acc: 0.7540\n","5m 49s (- 19m 50s) (17000 22%) loss: 0.0792 acc: 0.8140\n","6m 8s (- 19m 26s) (18000 24%) loss: 0.0807 acc: 0.8150\n","6m 28s (- 19m 5s) (19000 25%) loss: 0.0763 acc: 0.8020\n","6m 49s (- 18m 45s) (20000 26%) loss: 0.0718 acc: 0.7960\n","7m 9s (- 18m 25s) (21000 28%) loss: 0.0650 acc: 0.8220\n","7m 29s (- 18m 3s) (22000 29%) loss: 0.0581 acc: 0.8170\n","7m 51s (- 17m 44s) (23000 30%) loss: 0.0473 acc: 0.8560\n","8m 11s (- 17m 25s) (24000 32%) loss: 0.0598 acc: 0.8650\n","8m 32s (- 17m 4s) (25000 33%) loss: 0.0401 acc: 0.8620\n","8m 53s (- 16m 44s) (26000 34%) loss: 0.0506 acc: 0.8660\n","9m 13s (- 16m 23s) (27000 36%) loss: 0.0415 acc: 0.8850\n","9m 33s (- 16m 2s) (28000 37%) loss: 0.0441 acc: 0.8870\n","9m 53s (- 15m 42s) (29000 38%) loss: 0.0276 acc: 0.9110\n","10m 13s (- 15m 20s) (30000 40%) loss: 0.0384 acc: 0.8770\n","10m 34s (- 15m 0s) (31000 41%) loss: 0.0625 acc: 0.8930\n","10m 55s (- 14m 40s) (32000 42%) loss: 0.0249 acc: 0.9160\n","11m 15s (- 14m 19s) (33000 44%) loss: 0.0339 acc: 0.9200\n","11m 36s (- 13m 59s) (34000 45%) loss: 0.0216 acc: 0.9250\n","11m 56s (- 13m 38s) (35000 46%) loss: 0.0409 acc: 0.9210\n","12m 16s (- 13m 17s) (36000 48%) loss: 0.0189 acc: 0.9400\n","12m 36s (- 12m 56s) (37000 49%) loss: 0.0241 acc: 0.9450\n","12m 57s (- 12m 36s) (38000 50%) loss: 0.0360 acc: 0.9320\n","13m 17s (- 12m 15s) (39000 52%) loss: 0.0301 acc: 0.9280\n","13m 37s (- 11m 55s) (40000 53%) loss: 0.0095 acc: 0.9690\n","13m 59s (- 11m 35s) (41000 54%) loss: 0.0213 acc: 0.9510\n","14m 19s (- 11m 15s) (42000 56%) loss: 0.0144 acc: 0.9550\n","14m 40s (- 10m 55s) (43000 57%) loss: 0.0245 acc: 0.9440\n","15m 0s (- 10m 34s) (44000 58%) loss: 0.0127 acc: 0.9650\n","15m 20s (- 10m 13s) (45000 60%) loss: 0.0148 acc: 0.9590\n","15m 41s (- 9m 53s) (46000 61%) loss: 0.0163 acc: 0.9390\n","16m 1s (- 9m 32s) (47000 62%) loss: 0.0123 acc: 0.9610\n","16m 21s (- 9m 12s) (48000 64%) loss: 0.0182 acc: 0.9620\n","16m 42s (- 8m 51s) (49000 65%) loss: 0.0077 acc: 0.9740\n","17m 3s (- 8m 31s) (50000 66%) loss: 0.0171 acc: 0.9610\n","17m 24s (- 8m 11s) (51000 68%) loss: 0.0234 acc: 0.9600\n","17m 44s (- 7m 50s) (52000 69%) loss: 0.0175 acc: 0.9550\n","18m 4s (- 7m 30s) (53000 70%) loss: 0.0201 acc: 0.9470\n","18m 24s (- 7m 9s) (54000 72%) loss: 0.0171 acc: 0.9730\n","18m 45s (- 6m 49s) (55000 73%) loss: 0.0177 acc: 0.9670\n","19m 5s (- 6m 28s) (56000 74%) loss: 0.0065 acc: 0.9820\n","19m 25s (- 6m 8s) (57000 76%) loss: 0.0235 acc: 0.9770\n","19m 45s (- 5m 47s) (58000 77%) loss: 0.0116 acc: 0.9830\n","20m 6s (- 5m 27s) (59000 78%) loss: 0.0234 acc: 0.9550\n","20m 27s (- 5m 6s) (60000 80%) loss: 0.0201 acc: 0.9730\n","20m 47s (- 4m 46s) (61000 81%) loss: 0.0138 acc: 0.9770\n","21m 8s (- 4m 25s) (62000 82%) loss: 0.0132 acc: 0.9760\n","21m 28s (- 4m 5s) (63000 84%) loss: 0.0041 acc: 0.9840\n","21m 48s (- 3m 44s) (64000 85%) loss: 0.0146 acc: 0.9850\n","22m 8s (- 3m 24s) (65000 86%) loss: 0.0094 acc: 0.9820\n","22m 29s (- 3m 3s) (66000 88%) loss: 0.0121 acc: 0.9690\n","22m 49s (- 2m 43s) (67000 89%) loss: 0.0081 acc: 0.9730\n","23m 10s (- 2m 23s) (68000 90%) loss: 0.0075 acc: 0.9830\n","23m 30s (- 2m 2s) (69000 92%) loss: 0.0010 acc: 0.9940\n","23m 51s (- 1m 42s) (70000 93%) loss: 0.0099 acc: 0.9830\n","24m 11s (- 1m 21s) (71000 94%) loss: 0.0073 acc: 0.9880\n","24m 31s (- 1m 1s) (72000 96%) loss: 0.0037 acc: 0.9900\n","24m 51s (- 0m 40s) (73000 97%) loss: 0.0037 acc: 0.9850\n","25m 12s (- 0m 20s) (74000 98%) loss: 0.0322 acc: 0.9680\n","25m 32s (- 0m 0s) (75000 100%) loss: 0.0091 acc: 0.9790\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 7706/7706 [00:49<00:00, 155.44it/s]\n"]},{"output_type":"stream","name":"stdout","text":["0m 24s (- 29m 45s) (1000 1%) loss: 1.1238 acc: 0.0950\n","0m 44s (- 26m 46s) (2000 2%) loss: 0.7718 acc: 0.1170\n","1m 3s (- 25m 19s) (3000 4%) loss: 0.5679 acc: 0.1870\n","1m 22s (- 24m 31s) (4000 5%) loss: 0.4862 acc: 0.2220\n","1m 42s (- 23m 55s) (5000 6%) loss: 0.4219 acc: 0.2540\n","2m 2s (- 23m 27s) (6000 8%) loss: 0.3634 acc: 0.3330\n","2m 22s (- 23m 4s) (7000 9%) loss: 0.3394 acc: 0.3530\n","2m 42s (- 22m 41s) (8000 10%) loss: 0.3082 acc: 0.3670\n","3m 3s (- 22m 25s) (9000 12%) loss: 0.2627 acc: 0.4510\n","3m 23s (- 22m 0s) (10000 13%) loss: 0.2672 acc: 0.4780\n","3m 43s (- 21m 37s) (11000 14%) loss: 0.2075 acc: 0.5320\n","4m 3s (- 21m 16s) (12000 16%) loss: 0.1785 acc: 0.5600\n","4m 23s (- 20m 55s) (13000 17%) loss: 0.1575 acc: 0.6000\n","4m 43s (- 20m 35s) (14000 18%) loss: 0.1378 acc: 0.6240\n","5m 3s (- 20m 13s) (15000 20%) loss: 0.1131 acc: 0.6840\n","5m 23s (- 19m 52s) (16000 21%) loss: 0.1245 acc: 0.7010\n","5m 43s (- 19m 32s) (17000 22%) loss: 0.0928 acc: 0.7530\n","6m 4s (- 19m 13s) (18000 24%) loss: 0.0956 acc: 0.7590\n","6m 24s (- 18m 53s) (19000 25%) loss: 0.0633 acc: 0.8050\n","6m 45s (- 18m 34s) (20000 26%) loss: 0.0803 acc: 0.8060\n","7m 5s (- 18m 14s) (21000 28%) loss: 0.0664 acc: 0.7940\n","7m 25s (- 17m 54s) (22000 29%) loss: 0.0741 acc: 0.8110\n","7m 46s (- 17m 34s) (23000 30%) loss: 0.0567 acc: 0.8090\n","8m 6s (- 17m 13s) (24000 32%) loss: 0.0702 acc: 0.8200\n","8m 26s (- 16m 53s) (25000 33%) loss: 0.0558 acc: 0.8350\n","8m 46s (- 16m 32s) (26000 34%) loss: 0.0682 acc: 0.8580\n","9m 6s (- 16m 11s) (27000 36%) loss: 0.0461 acc: 0.8640\n","9m 27s (- 15m 52s) (28000 37%) loss: 0.0505 acc: 0.8640\n","9m 47s (- 15m 31s) (29000 38%) loss: 0.0406 acc: 0.8820\n","10m 7s (- 15m 10s) (30000 40%) loss: 0.0518 acc: 0.8750\n","10m 27s (- 14m 50s) (31000 41%) loss: 0.0498 acc: 0.8920\n","10m 47s (- 14m 30s) (32000 42%) loss: 0.0438 acc: 0.8870\n","11m 8s (- 14m 11s) (33000 44%) loss: 0.0420 acc: 0.8980\n","11m 28s (- 13m 50s) (34000 45%) loss: 0.0270 acc: 0.9210\n","11m 49s (- 13m 30s) (35000 46%) loss: 0.0234 acc: 0.9190\n","12m 10s (- 13m 10s) (36000 48%) loss: 0.0209 acc: 0.9080\n","12m 31s (- 12m 52s) (37000 49%) loss: 0.0396 acc: 0.9020\n","12m 52s (- 12m 32s) (38000 50%) loss: 0.0388 acc: 0.9050\n","13m 12s (- 12m 11s) (39000 52%) loss: 0.0320 acc: 0.9350\n","13m 32s (- 11m 51s) (40000 53%) loss: 0.0262 acc: 0.9180\n","13m 53s (- 11m 31s) (41000 54%) loss: 0.0225 acc: 0.9270\n","14m 14s (- 11m 11s) (42000 56%) loss: 0.0240 acc: 0.9400\n","14m 35s (- 10m 51s) (43000 57%) loss: 0.0221 acc: 0.9330\n","14m 55s (- 10m 31s) (44000 58%) loss: 0.0285 acc: 0.9510\n","15m 16s (- 10m 10s) (45000 60%) loss: 0.0299 acc: 0.9430\n","15m 37s (- 9m 51s) (46000 61%) loss: 0.0172 acc: 0.9440\n","15m 58s (- 9m 30s) (47000 62%) loss: 0.0098 acc: 0.9510\n","16m 18s (- 9m 10s) (48000 64%) loss: 0.0218 acc: 0.9460\n","16m 38s (- 8m 50s) (49000 65%) loss: 0.0134 acc: 0.9540\n","16m 59s (- 8m 29s) (50000 66%) loss: 0.0178 acc: 0.9520\n","17m 19s (- 8m 9s) (51000 68%) loss: 0.0246 acc: 0.9540\n","17m 40s (- 7m 49s) (52000 69%) loss: 0.0149 acc: 0.9590\n","18m 1s (- 7m 28s) (53000 70%) loss: 0.0121 acc: 0.9540\n","18m 21s (- 7m 8s) (54000 72%) loss: 0.0226 acc: 0.9500\n","18m 42s (- 6m 48s) (55000 73%) loss: 0.0260 acc: 0.9690\n","19m 2s (- 6m 27s) (56000 74%) loss: 0.0203 acc: 0.9600\n","19m 23s (- 6m 7s) (57000 76%) loss: 0.0122 acc: 0.9590\n","19m 43s (- 5m 46s) (58000 77%) loss: 0.0238 acc: 0.9690\n","20m 4s (- 5m 26s) (59000 78%) loss: 0.0232 acc: 0.9500\n","20m 24s (- 5m 6s) (60000 80%) loss: 0.0118 acc: 0.9740\n","20m 44s (- 4m 45s) (61000 81%) loss: 0.0056 acc: 0.9810\n","21m 4s (- 4m 25s) (62000 82%) loss: 0.0069 acc: 0.9760\n","21m 24s (- 4m 4s) (63000 84%) loss: 0.0081 acc: 0.9770\n","21m 45s (- 3m 44s) (64000 85%) loss: 0.0125 acc: 0.9690\n","22m 6s (- 3m 24s) (65000 86%) loss: 0.0187 acc: 0.9750\n","22m 26s (- 3m 3s) (66000 88%) loss: 0.0139 acc: 0.9660\n","22m 47s (- 2m 43s) (67000 89%) loss: 0.0064 acc: 0.9810\n","23m 8s (- 2m 22s) (68000 90%) loss: 0.0104 acc: 0.9630\n","23m 28s (- 2m 2s) (69000 92%) loss: 0.0151 acc: 0.9790\n","23m 48s (- 1m 42s) (70000 93%) loss: 0.0152 acc: 0.9700\n","24m 8s (- 1m 21s) (71000 94%) loss: 0.0050 acc: 0.9820\n","24m 28s (- 1m 1s) (72000 96%) loss: 0.0351 acc: 0.9760\n","24m 49s (- 0m 40s) (73000 97%) loss: 0.0111 acc: 0.9800\n","25m 10s (- 0m 20s) (74000 98%) loss: 0.0095 acc: 0.9670\n","25m 30s (- 0m 0s) (75000 100%) loss: 0.0036 acc: 0.9870\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 7706/7706 [00:51<00:00, 150.32it/s]\n"]},{"output_type":"stream","name":"stdout","text":["0m 24s (- 29m 46s) (1000 1%) loss: 1.1018 acc: 0.1000\n","0m 43s (- 26m 44s) (2000 2%) loss: 0.6814 acc: 0.1180\n","1m 4s (- 25m 38s) (3000 4%) loss: 0.5209 acc: 0.1670\n","1m 25s (- 25m 10s) (4000 5%) loss: 0.4690 acc: 0.2150\n","1m 44s (- 24m 26s) (5000 6%) loss: 0.4048 acc: 0.2780\n","2m 4s (- 23m 55s) (6000 8%) loss: 0.3549 acc: 0.3040\n","2m 25s (- 23m 30s) (7000 9%) loss: 0.3151 acc: 0.3670\n","2m 45s (- 23m 5s) (8000 10%) loss: 0.3228 acc: 0.4260\n","3m 5s (- 22m 42s) (9000 12%) loss: 0.2594 acc: 0.4410\n","3m 25s (- 22m 18s) (10000 13%) loss: 0.2180 acc: 0.5210\n","3m 46s (- 21m 55s) (11000 14%) loss: 0.2008 acc: 0.5540\n","4m 6s (- 21m 35s) (12000 16%) loss: 0.1718 acc: 0.5700\n","4m 27s (- 21m 15s) (13000 17%) loss: 0.1608 acc: 0.6150\n","4m 47s (- 20m 53s) (14000 18%) loss: 0.1358 acc: 0.6510\n","5m 7s (- 20m 31s) (15000 20%) loss: 0.1116 acc: 0.6580\n","5m 28s (- 20m 10s) (16000 21%) loss: 0.1130 acc: 0.6930\n","5m 48s (- 19m 49s) (17000 22%) loss: 0.0881 acc: 0.7580\n","6m 8s (- 19m 27s) (18000 24%) loss: 0.0787 acc: 0.7720\n","6m 28s (- 19m 5s) (19000 25%) loss: 0.0862 acc: 0.7980\n","6m 48s (- 18m 43s) (20000 26%) loss: 0.0709 acc: 0.8080\n","7m 8s (- 18m 22s) (21000 28%) loss: 0.0608 acc: 0.8440\n","7m 30s (- 18m 4s) (22000 29%) loss: 0.0746 acc: 0.8330\n","7m 50s (- 17m 43s) (23000 30%) loss: 0.0729 acc: 0.8340\n","8m 10s (- 17m 21s) (24000 32%) loss: 0.0435 acc: 0.8800\n","8m 30s (- 17m 0s) (25000 33%) loss: 0.0490 acc: 0.8520\n","8m 49s (- 16m 38s) (26000 34%) loss: 0.0641 acc: 0.8910\n","9m 10s (- 16m 18s) (27000 36%) loss: 0.0548 acc: 0.8720\n","9m 30s (- 15m 57s) (28000 37%) loss: 0.0268 acc: 0.8890\n","9m 50s (- 15m 37s) (29000 38%) loss: 0.0425 acc: 0.8710\n","10m 11s (- 15m 16s) (30000 40%) loss: 0.0315 acc: 0.9140\n","10m 32s (- 14m 57s) (31000 41%) loss: 0.0375 acc: 0.9110\n","10m 53s (- 14m 37s) (32000 42%) loss: 0.0350 acc: 0.9240\n","11m 13s (- 14m 16s) (33000 44%) loss: 0.0399 acc: 0.9170\n","11m 33s (- 13m 56s) (34000 45%) loss: 0.0295 acc: 0.9320\n","11m 53s (- 13m 35s) (35000 46%) loss: 0.0345 acc: 0.9360\n","12m 13s (- 13m 15s) (36000 48%) loss: 0.0183 acc: 0.9370\n","12m 34s (- 12m 55s) (37000 49%) loss: 0.0227 acc: 0.9330\n","12m 54s (- 12m 34s) (38000 50%) loss: 0.0177 acc: 0.9460\n","13m 14s (- 12m 13s) (39000 52%) loss: 0.0277 acc: 0.9440\n","13m 36s (- 11m 54s) (40000 53%) loss: 0.0184 acc: 0.9530\n","13m 56s (- 11m 33s) (41000 54%) loss: 0.0093 acc: 0.9740\n","14m 16s (- 11m 13s) (42000 56%) loss: 0.0123 acc: 0.9590\n","14m 37s (- 10m 53s) (43000 57%) loss: 0.0274 acc: 0.9550\n","14m 58s (- 10m 32s) (44000 58%) loss: 0.0233 acc: 0.9540\n","15m 18s (- 10m 12s) (45000 60%) loss: 0.0103 acc: 0.9760\n","15m 39s (- 9m 52s) (46000 61%) loss: 0.0215 acc: 0.9580\n","15m 59s (- 9m 31s) (47000 62%) loss: 0.0183 acc: 0.9660\n","16m 19s (- 9m 10s) (48000 64%) loss: 0.0270 acc: 0.9590\n","16m 40s (- 8m 51s) (49000 65%) loss: 0.0055 acc: 0.9830\n","17m 1s (- 8m 30s) (50000 66%) loss: 0.0100 acc: 0.9790\n","17m 22s (- 8m 10s) (51000 68%) loss: 0.0192 acc: 0.9660\n","17m 42s (- 7m 49s) (52000 69%) loss: 0.0204 acc: 0.9740\n","18m 2s (- 7m 29s) (53000 70%) loss: 0.0266 acc: 0.9740\n","18m 23s (- 7m 8s) (54000 72%) loss: 0.0047 acc: 0.9760\n","18m 43s (- 6m 48s) (55000 73%) loss: 0.0080 acc: 0.9710\n","19m 4s (- 6m 28s) (56000 74%) loss: 0.0172 acc: 0.9790\n","19m 24s (- 6m 7s) (57000 76%) loss: 0.0075 acc: 0.9830\n","19m 45s (- 5m 47s) (58000 77%) loss: 0.0016 acc: 0.9930\n","20m 6s (- 5m 27s) (59000 78%) loss: 0.0039 acc: 0.9820\n","20m 26s (- 5m 6s) (60000 80%) loss: 0.0103 acc: 0.9690\n","20m 46s (- 4m 46s) (61000 81%) loss: 0.0060 acc: 0.9780\n","21m 6s (- 4m 25s) (62000 82%) loss: 0.0038 acc: 0.9880\n","21m 27s (- 4m 5s) (63000 84%) loss: 0.0083 acc: 0.9790\n","21m 47s (- 3m 44s) (64000 85%) loss: 0.0127 acc: 0.9860\n","22m 7s (- 3m 24s) (65000 86%) loss: 0.0048 acc: 0.9820\n","22m 28s (- 3m 3s) (66000 88%) loss: 0.0069 acc: 0.9800\n","22m 49s (- 2m 43s) (67000 89%) loss: 0.0141 acc: 0.9820\n","23m 9s (- 2m 23s) (68000 90%) loss: 0.0098 acc: 0.9840\n","23m 30s (- 2m 2s) (69000 92%) loss: 0.0136 acc: 0.9840\n","23m 49s (- 1m 42s) (70000 93%) loss: 0.0107 acc: 0.9780\n","24m 10s (- 1m 21s) (71000 94%) loss: 0.0030 acc: 0.9850\n","24m 30s (- 1m 1s) (72000 96%) loss: 0.0021 acc: 0.9900\n","24m 51s (- 0m 40s) (73000 97%) loss: 0.0055 acc: 0.9870\n","25m 11s (- 0m 20s) (74000 98%) loss: 0.0038 acc: 0.9840\n","25m 30s (- 0m 0s) (75000 100%) loss: 0.0064 acc: 0.9870\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 7706/7706 [00:51<00:00, 150.42it/s]\n"]},{"output_type":"stream","name":"stdout","text":["0m 24s (- 30m 39s) (1000 1%) loss: 1.1031 acc: 0.0800\n","0m 44s (- 27m 12s) (2000 2%) loss: 0.7021 acc: 0.1320\n","1m 4s (- 25m 47s) (3000 4%) loss: 0.5386 acc: 0.1760\n","1m 24s (- 25m 0s) (4000 5%) loss: 0.4563 acc: 0.2160\n","1m 44s (- 24m 25s) (5000 6%) loss: 0.4234 acc: 0.2570\n","2m 4s (- 23m 53s) (6000 8%) loss: 0.3644 acc: 0.3200\n","2m 25s (- 23m 31s) (7000 9%) loss: 0.3260 acc: 0.3670\n","2m 45s (- 23m 4s) (8000 10%) loss: 0.3269 acc: 0.3630\n","3m 5s (- 22m 41s) (9000 12%) loss: 0.2696 acc: 0.4370\n","3m 26s (- 22m 19s) (10000 13%) loss: 0.2541 acc: 0.4750\n","3m 45s (- 21m 54s) (11000 14%) loss: 0.2243 acc: 0.5200\n","4m 5s (- 21m 30s) (12000 16%) loss: 0.2121 acc: 0.5390\n","4m 26s (- 21m 9s) (13000 17%) loss: 0.1711 acc: 0.5860\n","4m 46s (- 20m 48s) (14000 18%) loss: 0.1728 acc: 0.6100\n","5m 6s (- 20m 26s) (15000 20%) loss: 0.1241 acc: 0.6330\n","5m 27s (- 20m 7s) (16000 21%) loss: 0.1239 acc: 0.6590\n","5m 47s (- 19m 46s) (17000 22%) loss: 0.1117 acc: 0.6740\n","6m 7s (- 19m 24s) (18000 24%) loss: 0.1209 acc: 0.7040\n","6m 27s (- 19m 2s) (19000 25%) loss: 0.1212 acc: 0.7080\n","6m 47s (- 18m 41s) (20000 26%) loss: 0.1139 acc: 0.7100\n","7m 8s (- 18m 20s) (21000 28%) loss: 0.0870 acc: 0.7220\n","7m 28s (- 18m 0s) (22000 29%) loss: 0.0841 acc: 0.7280\n","7m 48s (- 17m 39s) (23000 30%) loss: 0.0714 acc: 0.7490\n","8m 8s (- 17m 18s) (24000 32%) loss: 0.0725 acc: 0.7620\n","8m 30s (- 17m 0s) (25000 33%) loss: 0.0733 acc: 0.7550\n","8m 50s (- 16m 39s) (26000 34%) loss: 0.0586 acc: 0.7900\n","9m 10s (- 16m 18s) (27000 36%) loss: 0.0539 acc: 0.7930\n","9m 31s (- 15m 58s) (28000 37%) loss: 0.0552 acc: 0.7950\n","9m 51s (- 15m 38s) (29000 38%) loss: 0.0707 acc: 0.7890\n","10m 11s (- 15m 17s) (30000 40%) loss: 0.0542 acc: 0.8230\n","10m 32s (- 14m 57s) (31000 41%) loss: 0.0508 acc: 0.8180\n","10m 53s (- 14m 37s) (32000 42%) loss: 0.0518 acc: 0.8220\n","11m 13s (- 14m 17s) (33000 44%) loss: 0.0393 acc: 0.8330\n","11m 35s (- 13m 58s) (34000 45%) loss: 0.0562 acc: 0.8200\n","11m 55s (- 13m 38s) (35000 46%) loss: 0.0492 acc: 0.8430\n","12m 16s (- 13m 17s) (36000 48%) loss: 0.0308 acc: 0.8600\n","12m 37s (- 12m 57s) (37000 49%) loss: 0.0382 acc: 0.8510\n","12m 57s (- 12m 36s) (38000 50%) loss: 0.0356 acc: 0.8590\n","13m 17s (- 12m 16s) (39000 52%) loss: 0.0350 acc: 0.8730\n","13m 37s (- 11m 55s) (40000 53%) loss: 0.0492 acc: 0.8730\n","13m 57s (- 11m 34s) (41000 54%) loss: 0.0387 acc: 0.8840\n","14m 18s (- 11m 14s) (42000 56%) loss: 0.0282 acc: 0.8770\n","14m 40s (- 10m 54s) (43000 57%) loss: 0.0480 acc: 0.8960\n","15m 1s (- 10m 34s) (44000 58%) loss: 0.0299 acc: 0.8790\n","15m 21s (- 10m 14s) (45000 60%) loss: 0.0574 acc: 0.8920\n","15m 42s (- 9m 53s) (46000 61%) loss: 0.0298 acc: 0.8910\n","16m 2s (- 9m 33s) (47000 62%) loss: 0.0210 acc: 0.9080\n","16m 22s (- 9m 12s) (48000 64%) loss: 0.0293 acc: 0.9130\n","16m 43s (- 8m 52s) (49000 65%) loss: 0.0224 acc: 0.9290\n","17m 4s (- 8m 32s) (50000 66%) loss: 0.0182 acc: 0.9280\n","17m 25s (- 8m 11s) (51000 68%) loss: 0.0240 acc: 0.9300\n","17m 46s (- 7m 51s) (52000 69%) loss: 0.0127 acc: 0.9560\n","18m 6s (- 7m 30s) (53000 70%) loss: 0.0221 acc: 0.9360\n","18m 27s (- 7m 10s) (54000 72%) loss: 0.0205 acc: 0.9330\n","18m 48s (- 6m 50s) (55000 73%) loss: 0.0347 acc: 0.9080\n","19m 8s (- 6m 29s) (56000 74%) loss: 0.0261 acc: 0.9440\n","19m 29s (- 6m 9s) (57000 76%) loss: 0.0148 acc: 0.9670\n","19m 48s (- 5m 48s) (58000 77%) loss: 0.0136 acc: 0.9590\n","20m 8s (- 5m 27s) (59000 78%) loss: 0.0132 acc: 0.9650\n","20m 29s (- 5m 7s) (60000 80%) loss: 0.0115 acc: 0.9540\n","20m 50s (- 4m 47s) (61000 81%) loss: 0.0260 acc: 0.9540\n","21m 10s (- 4m 26s) (62000 82%) loss: 0.0150 acc: 0.9540\n","21m 31s (- 4m 5s) (63000 84%) loss: 0.0083 acc: 0.9630\n","21m 51s (- 3m 45s) (64000 85%) loss: 0.0259 acc: 0.9600\n","22m 12s (- 3m 24s) (65000 86%) loss: 0.0190 acc: 0.9520\n","22m 32s (- 3m 4s) (66000 88%) loss: 0.0244 acc: 0.9730\n","22m 53s (- 2m 43s) (67000 89%) loss: 0.0135 acc: 0.9540\n","23m 13s (- 2m 23s) (68000 90%) loss: 0.0047 acc: 0.9740\n","23m 34s (- 2m 3s) (69000 92%) loss: 0.0099 acc: 0.9730\n","23m 55s (- 1m 42s) (70000 93%) loss: 0.0063 acc: 0.9710\n","24m 15s (- 1m 22s) (71000 94%) loss: 0.0163 acc: 0.9830\n","24m 36s (- 1m 1s) (72000 96%) loss: 0.0139 acc: 0.9620\n","24m 56s (- 0m 41s) (73000 97%) loss: 0.0165 acc: 0.9570\n","25m 17s (- 0m 20s) (74000 98%) loss: 0.0042 acc: 0.9820\n","25m 37s (- 0m 0s) (75000 100%) loss: 0.0139 acc: 0.9770\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 7706/7706 [00:51<00:00, 149.16it/s]\n"]},{"output_type":"stream","name":"stdout","text":["0m 24s (- 30m 32s) (1000 1%) loss: 1.0923 acc: 0.0930\n","0m 44s (- 27m 15s) (2000 2%) loss: 0.7113 acc: 0.1270\n","1m 5s (- 26m 0s) (3000 4%) loss: 0.5423 acc: 0.1660\n","1m 25s (- 25m 14s) (4000 5%) loss: 0.4579 acc: 0.2330\n","1m 45s (- 24m 35s) (5000 6%) loss: 0.4114 acc: 0.2770\n","2m 5s (- 24m 5s) (6000 8%) loss: 0.3563 acc: 0.3160\n","2m 25s (- 23m 34s) (7000 9%) loss: 0.3153 acc: 0.3880\n","2m 45s (- 23m 7s) (8000 10%) loss: 0.3155 acc: 0.4160\n","3m 7s (- 22m 53s) (9000 12%) loss: 0.2753 acc: 0.4460\n","3m 27s (- 22m 27s) (10000 13%) loss: 0.2375 acc: 0.5030\n","3m 47s (- 22m 3s) (11000 14%) loss: 0.2419 acc: 0.5160\n","4m 7s (- 21m 39s) (12000 16%) loss: 0.2108 acc: 0.5580\n","4m 27s (- 21m 15s) (13000 17%) loss: 0.1795 acc: 0.6090\n","4m 47s (- 20m 53s) (14000 18%) loss: 0.1544 acc: 0.6170\n","5m 8s (- 20m 32s) (15000 20%) loss: 0.1416 acc: 0.6380\n","5m 28s (- 20m 9s) (16000 21%) loss: 0.1138 acc: 0.7260\n","5m 48s (- 19m 48s) (17000 22%) loss: 0.1206 acc: 0.7410\n","6m 9s (- 19m 30s) (18000 24%) loss: 0.1065 acc: 0.7690\n","6m 29s (- 19m 8s) (19000 25%) loss: 0.0766 acc: 0.7760\n","6m 50s (- 18m 48s) (20000 26%) loss: 0.0788 acc: 0.7710\n","7m 11s (- 18m 29s) (21000 28%) loss: 0.0929 acc: 0.7950\n","7m 31s (- 18m 8s) (22000 29%) loss: 0.0807 acc: 0.8130\n","7m 52s (- 17m 47s) (23000 30%) loss: 0.0579 acc: 0.8310\n","8m 12s (- 17m 26s) (24000 32%) loss: 0.0732 acc: 0.8260\n","8m 32s (- 17m 4s) (25000 33%) loss: 0.0427 acc: 0.8450\n","8m 53s (- 16m 44s) (26000 34%) loss: 0.0702 acc: 0.8410\n","9m 13s (- 16m 23s) (27000 36%) loss: 0.0655 acc: 0.8540\n","9m 33s (- 16m 2s) (28000 37%) loss: 0.0506 acc: 0.8740\n","9m 54s (- 15m 42s) (29000 38%) loss: 0.0620 acc: 0.8700\n","10m 14s (- 15m 21s) (30000 40%) loss: 0.0582 acc: 0.8700\n","10m 34s (- 15m 0s) (31000 41%) loss: 0.0393 acc: 0.8930\n","10m 55s (- 14m 40s) (32000 42%) loss: 0.0386 acc: 0.8920\n","11m 15s (- 14m 20s) (33000 44%) loss: 0.0316 acc: 0.8890\n","11m 37s (- 14m 0s) (34000 45%) loss: 0.0544 acc: 0.8760\n","11m 57s (- 13m 40s) (35000 46%) loss: 0.0238 acc: 0.9170\n","12m 18s (- 13m 19s) (36000 48%) loss: 0.0360 acc: 0.9060\n","12m 38s (- 12m 58s) (37000 49%) loss: 0.0568 acc: 0.9060\n","12m 59s (- 12m 38s) (38000 50%) loss: 0.0275 acc: 0.9040\n","13m 19s (- 12m 18s) (39000 52%) loss: 0.0236 acc: 0.9140\n","13m 40s (- 11m 57s) (40000 53%) loss: 0.0319 acc: 0.9330\n","14m 0s (- 11m 36s) (41000 54%) loss: 0.0253 acc: 0.9230\n","14m 21s (- 11m 16s) (42000 56%) loss: 0.0379 acc: 0.9080\n","14m 42s (- 10m 56s) (43000 57%) loss: 0.0288 acc: 0.9430\n","15m 2s (- 10m 35s) (44000 58%) loss: 0.0163 acc: 0.9410\n","15m 22s (- 10m 15s) (45000 60%) loss: 0.0216 acc: 0.9500\n","15m 43s (- 9m 54s) (46000 61%) loss: 0.0193 acc: 0.9450\n","16m 3s (- 9m 33s) (47000 62%) loss: 0.0306 acc: 0.9420\n","16m 23s (- 9m 13s) (48000 64%) loss: 0.0255 acc: 0.9260\n","16m 44s (- 8m 52s) (49000 65%) loss: 0.0211 acc: 0.9610\n","17m 5s (- 8m 32s) (50000 66%) loss: 0.0292 acc: 0.9470\n","17m 26s (- 8m 12s) (51000 68%) loss: 0.0239 acc: 0.9520\n","17m 46s (- 7m 51s) (52000 69%) loss: 0.0309 acc: 0.9460\n","18m 7s (- 7m 31s) (53000 70%) loss: 0.0114 acc: 0.9580\n","18m 27s (- 7m 10s) (54000 72%) loss: 0.0076 acc: 0.9710\n","18m 47s (- 6m 50s) (55000 73%) loss: 0.0199 acc: 0.9540\n","19m 8s (- 6m 29s) (56000 74%) loss: 0.0241 acc: 0.9560\n","19m 28s (- 6m 9s) (57000 76%) loss: 0.0082 acc: 0.9730\n","19m 49s (- 5m 48s) (58000 77%) loss: 0.0081 acc: 0.9690\n","20m 9s (- 5m 27s) (59000 78%) loss: 0.0231 acc: 0.9770\n","20m 30s (- 5m 7s) (60000 80%) loss: 0.0154 acc: 0.9610\n","20m 51s (- 4m 47s) (61000 81%) loss: 0.0257 acc: 0.9670\n","21m 12s (- 4m 26s) (62000 82%) loss: 0.0094 acc: 0.9640\n","21m 32s (- 4m 6s) (63000 84%) loss: 0.0062 acc: 0.9760\n","21m 52s (- 3m 45s) (64000 85%) loss: 0.0250 acc: 0.9720\n","22m 13s (- 3m 25s) (65000 86%) loss: 0.0131 acc: 0.9750\n","22m 33s (- 3m 4s) (66000 88%) loss: 0.0078 acc: 0.9710\n","22m 54s (- 2m 44s) (67000 89%) loss: 0.0144 acc: 0.9650\n","23m 15s (- 2m 23s) (68000 90%) loss: 0.0133 acc: 0.9760\n","23m 36s (- 2m 3s) (69000 92%) loss: 0.0105 acc: 0.9840\n","23m 56s (- 1m 42s) (70000 93%) loss: 0.0027 acc: 0.9880\n","24m 16s (- 1m 22s) (71000 94%) loss: 0.0203 acc: 0.9670\n","24m 37s (- 1m 1s) (72000 96%) loss: 0.0063 acc: 0.9770\n","24m 57s (- 0m 41s) (73000 97%) loss: 0.0126 acc: 0.9760\n","25m 17s (- 0m 20s) (74000 98%) loss: 0.0096 acc: 0.9820\n","25m 37s (- 0m 0s) (75000 100%) loss: 0.0147 acc: 0.9840\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 7706/7706 [01:00<00:00, 126.35it/s]\n"]},{"output_type":"stream","name":"stdout","text":["0m 24s (- 30m 1s) (1000 1%) loss: 1.0798 acc: 0.0940\n","0m 43s (- 26m 44s) (2000 2%) loss: 0.6674 acc: 0.1360\n","1m 3s (- 25m 29s) (3000 4%) loss: 0.5452 acc: 0.1880\n","1m 23s (- 24m 45s) (4000 5%) loss: 0.4484 acc: 0.2400\n","1m 43s (- 24m 14s) (5000 6%) loss: 0.4066 acc: 0.2850\n","2m 3s (- 23m 40s) (6000 8%) loss: 0.3838 acc: 0.3350\n","2m 23s (- 23m 18s) (7000 9%) loss: 0.3082 acc: 0.3700\n","2m 45s (- 23m 5s) (8000 10%) loss: 0.2642 acc: 0.4430\n","3m 6s (- 22m 45s) (9000 12%) loss: 0.2524 acc: 0.4750\n","3m 26s (- 22m 19s) (10000 13%) loss: 0.2497 acc: 0.5260\n","3m 46s (- 21m 57s) (11000 14%) loss: 0.1716 acc: 0.5560\n","4m 6s (- 21m 33s) (12000 16%) loss: 0.1722 acc: 0.6270\n","4m 26s (- 21m 8s) (13000 17%) loss: 0.1352 acc: 0.6390\n","4m 46s (- 20m 48s) (14000 18%) loss: 0.1261 acc: 0.6490\n","5m 6s (- 20m 27s) (15000 20%) loss: 0.0924 acc: 0.7180\n","5m 27s (- 20m 9s) (16000 21%) loss: 0.1024 acc: 0.6880\n","5m 48s (- 19m 49s) (17000 22%) loss: 0.0869 acc: 0.7210\n","6m 9s (- 19m 28s) (18000 24%) loss: 0.0752 acc: 0.7640\n","6m 29s (- 19m 8s) (19000 25%) loss: 0.0716 acc: 0.7600\n","6m 50s (- 18m 49s) (20000 26%) loss: 0.0790 acc: 0.7960\n","7m 11s (- 18m 28s) (21000 28%) loss: 0.0614 acc: 0.8220\n","7m 32s (- 18m 9s) (22000 29%) loss: 0.0701 acc: 0.8220\n","7m 52s (- 17m 47s) (23000 30%) loss: 0.0548 acc: 0.8640\n","8m 13s (- 17m 29s) (24000 32%) loss: 0.0558 acc: 0.8450\n","8m 34s (- 17m 9s) (25000 33%) loss: 0.0776 acc: 0.8410\n","8m 54s (- 16m 48s) (26000 34%) loss: 0.0329 acc: 0.8790\n","9m 15s (- 16m 26s) (27000 36%) loss: 0.0358 acc: 0.8890\n","9m 35s (- 16m 6s) (28000 37%) loss: 0.0355 acc: 0.8960\n","9m 56s (- 15m 46s) (29000 38%) loss: 0.0330 acc: 0.9090\n","10m 16s (- 15m 25s) (30000 40%) loss: 0.0396 acc: 0.8900\n","10m 37s (- 15m 4s) (31000 41%) loss: 0.0292 acc: 0.9060\n","10m 58s (- 14m 45s) (32000 42%) loss: 0.0355 acc: 0.9340\n","11m 18s (- 14m 23s) (33000 44%) loss: 0.0442 acc: 0.9170\n","11m 39s (- 14m 3s) (34000 45%) loss: 0.0228 acc: 0.9100\n","11m 59s (- 13m 42s) (35000 46%) loss: 0.0183 acc: 0.9410\n","12m 20s (- 13m 21s) (36000 48%) loss: 0.0429 acc: 0.9270\n","12m 40s (- 13m 1s) (37000 49%) loss: 0.0164 acc: 0.9280\n","13m 1s (- 12m 41s) (38000 50%) loss: 0.0163 acc: 0.9510\n","13m 22s (- 12m 20s) (39000 52%) loss: 0.0104 acc: 0.9490\n","13m 43s (- 12m 0s) (40000 53%) loss: 0.0166 acc: 0.9410\n","14m 4s (- 11m 40s) (41000 54%) loss: 0.0249 acc: 0.9360\n","14m 25s (- 11m 20s) (42000 56%) loss: 0.0287 acc: 0.9620\n","14m 47s (- 11m 0s) (43000 57%) loss: 0.0142 acc: 0.9550\n","15m 8s (- 10m 39s) (44000 58%) loss: 0.0249 acc: 0.9490\n","15m 28s (- 10m 19s) (45000 60%) loss: 0.0109 acc: 0.9610\n","15m 49s (- 9m 58s) (46000 61%) loss: 0.0174 acc: 0.9600\n","16m 10s (- 9m 38s) (47000 62%) loss: 0.0163 acc: 0.9670\n","16m 32s (- 9m 18s) (48000 64%) loss: 0.0091 acc: 0.9670\n","16m 53s (- 8m 57s) (49000 65%) loss: 0.0185 acc: 0.9680\n","17m 13s (- 8m 36s) (50000 66%) loss: 0.0278 acc: 0.9600\n","17m 34s (- 8m 16s) (51000 68%) loss: 0.0209 acc: 0.9720\n","17m 54s (- 7m 55s) (52000 69%) loss: 0.0204 acc: 0.9540\n","18m 15s (- 7m 34s) (53000 70%) loss: 0.0113 acc: 0.9610\n","18m 36s (- 7m 14s) (54000 72%) loss: 0.0161 acc: 0.9650\n","18m 56s (- 6m 53s) (55000 73%) loss: 0.0211 acc: 0.9630\n","19m 18s (- 6m 33s) (56000 74%) loss: 0.0104 acc: 0.9770\n","19m 39s (- 6m 12s) (57000 76%) loss: 0.0091 acc: 0.9660\n","20m 0s (- 5m 51s) (58000 77%) loss: 0.0125 acc: 0.9650\n","20m 21s (- 5m 31s) (59000 78%) loss: 0.0067 acc: 0.9760\n","20m 41s (- 5m 10s) (60000 80%) loss: 0.0060 acc: 0.9760\n","21m 2s (- 4m 49s) (61000 81%) loss: 0.0053 acc: 0.9850\n","21m 23s (- 4m 29s) (62000 82%) loss: 0.0042 acc: 0.9880\n","21m 44s (- 4m 8s) (63000 84%) loss: 0.0158 acc: 0.9750\n","22m 5s (- 3m 47s) (64000 85%) loss: 0.0074 acc: 0.9790\n","22m 25s (- 3m 27s) (65000 86%) loss: 0.0058 acc: 0.9890\n","22m 46s (- 3m 6s) (66000 88%) loss: 0.0174 acc: 0.9810\n","23m 7s (- 2m 45s) (67000 89%) loss: 0.0112 acc: 0.9860\n","23m 26s (- 2m 24s) (68000 90%) loss: 0.0088 acc: 0.9700\n","23m 48s (- 2m 4s) (69000 92%) loss: 0.0072 acc: 0.9790\n","24m 8s (- 1m 43s) (70000 93%) loss: 0.0102 acc: 0.9790\n","24m 29s (- 1m 22s) (71000 94%) loss: 0.0184 acc: 0.9620\n","24m 51s (- 1m 2s) (72000 96%) loss: 0.0191 acc: 0.9800\n","25m 11s (- 0m 41s) (73000 97%) loss: 0.0021 acc: 0.9860\n","25m 32s (- 0m 20s) (74000 98%) loss: 0.0059 acc: 0.9820\n","25m 53s (- 0m 0s) (75000 100%) loss: 0.0133 acc: 0.9730\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 7706/7706 [00:53<00:00, 144.02it/s]\n"]},{"output_type":"stream","name":"stdout","text":["0m 24s (- 30m 35s) (1000 1%) loss: 1.1103 acc: 0.0860\n","0m 46s (- 28m 11s) (2000 2%) loss: 0.6949 acc: 0.1190\n","1m 6s (- 26m 45s) (3000 4%) loss: 0.5362 acc: 0.1640\n","1m 27s (- 25m 51s) (4000 5%) loss: 0.4570 acc: 0.2100\n","1m 47s (- 25m 9s) (5000 6%) loss: 0.3902 acc: 0.2800\n","2m 8s (- 24m 39s) (6000 8%) loss: 0.3495 acc: 0.3140\n","2m 29s (- 24m 8s) (7000 9%) loss: 0.3225 acc: 0.3480\n","2m 49s (- 23m 35s) (8000 10%) loss: 0.3121 acc: 0.4160\n","3m 8s (- 23m 4s) (9000 12%) loss: 0.2652 acc: 0.4800\n","3m 29s (- 22m 44s) (10000 13%) loss: 0.2113 acc: 0.5150\n","3m 50s (- 22m 21s) (11000 14%) loss: 0.1909 acc: 0.5660\n","4m 10s (- 21m 56s) (12000 16%) loss: 0.1881 acc: 0.6250\n","4m 31s (- 21m 34s) (13000 17%) loss: 0.1618 acc: 0.6500\n","4m 51s (- 21m 9s) (14000 18%) loss: 0.1363 acc: 0.6850\n","5m 12s (- 20m 48s) (15000 20%) loss: 0.1314 acc: 0.6930\n","5m 32s (- 20m 26s) (16000 21%) loss: 0.1107 acc: 0.7400\n","5m 53s (- 20m 5s) (17000 22%) loss: 0.1025 acc: 0.7220\n","6m 12s (- 19m 41s) (18000 24%) loss: 0.0845 acc: 0.8030\n","6m 34s (- 19m 22s) (19000 25%) loss: 0.1237 acc: 0.7690\n","6m 54s (- 18m 59s) (20000 26%) loss: 0.0768 acc: 0.7760\n","7m 14s (- 18m 37s) (21000 28%) loss: 0.0728 acc: 0.8140\n","7m 34s (- 18m 16s) (22000 29%) loss: 0.0819 acc: 0.8190\n","7m 55s (- 17m 54s) (23000 30%) loss: 0.0721 acc: 0.8280\n","8m 16s (- 17m 34s) (24000 32%) loss: 0.0602 acc: 0.8380\n","8m 35s (- 17m 11s) (25000 33%) loss: 0.0498 acc: 0.8580\n","8m 56s (- 16m 50s) (26000 34%) loss: 0.0485 acc: 0.8490\n","9m 17s (- 16m 31s) (27000 36%) loss: 0.0573 acc: 0.8600\n","9m 38s (- 16m 10s) (28000 37%) loss: 0.0488 acc: 0.8640\n","9m 58s (- 15m 49s) (29000 38%) loss: 0.0447 acc: 0.8800\n","10m 18s (- 15m 28s) (30000 40%) loss: 0.0478 acc: 0.8890\n","10m 39s (- 15m 8s) (31000 41%) loss: 0.0570 acc: 0.8590\n","10m 59s (- 14m 46s) (32000 42%) loss: 0.0299 acc: 0.9010\n","11m 19s (- 14m 24s) (33000 44%) loss: 0.0244 acc: 0.9110\n","11m 39s (- 14m 3s) (34000 45%) loss: 0.0347 acc: 0.9070\n","12m 1s (- 13m 44s) (35000 46%) loss: 0.0389 acc: 0.9190\n","12m 21s (- 13m 23s) (36000 48%) loss: 0.0260 acc: 0.9210\n","12m 42s (- 13m 2s) (37000 49%) loss: 0.0259 acc: 0.9150\n","13m 3s (- 12m 42s) (38000 50%) loss: 0.0280 acc: 0.9230\n","13m 23s (- 12m 22s) (39000 52%) loss: 0.0167 acc: 0.9330\n","13m 44s (- 12m 1s) (40000 53%) loss: 0.0193 acc: 0.9470\n","14m 5s (- 11m 40s) (41000 54%) loss: 0.0307 acc: 0.9260\n","14m 26s (- 11m 20s) (42000 56%) loss: 0.0150 acc: 0.9510\n","14m 48s (- 11m 0s) (43000 57%) loss: 0.0355 acc: 0.9510\n","15m 7s (- 10m 39s) (44000 58%) loss: 0.0144 acc: 0.9450\n","15m 28s (- 10m 19s) (45000 60%) loss: 0.0217 acc: 0.9380\n","15m 48s (- 9m 58s) (46000 61%) loss: 0.0187 acc: 0.9560\n","16m 9s (- 9m 37s) (47000 62%) loss: 0.0287 acc: 0.9510\n","16m 30s (- 9m 17s) (48000 64%) loss: 0.0152 acc: 0.9470\n","16m 50s (- 8m 56s) (49000 65%) loss: 0.0119 acc: 0.9630\n","17m 10s (- 8m 35s) (50000 66%) loss: 0.0118 acc: 0.9580\n","17m 32s (- 8m 15s) (51000 68%) loss: 0.0097 acc: 0.9680\n","17m 52s (- 7m 54s) (52000 69%) loss: 0.0118 acc: 0.9520\n","18m 13s (- 7m 33s) (53000 70%) loss: 0.0139 acc: 0.9550\n","18m 33s (- 7m 13s) (54000 72%) loss: 0.0166 acc: 0.9500\n","18m 54s (- 6m 52s) (55000 73%) loss: 0.0235 acc: 0.9420\n","19m 14s (- 6m 31s) (56000 74%) loss: 0.0151 acc: 0.9760\n","19m 35s (- 6m 11s) (57000 76%) loss: 0.0214 acc: 0.9640\n","19m 56s (- 5m 50s) (58000 77%) loss: 0.0125 acc: 0.9660\n","20m 16s (- 5m 29s) (59000 78%) loss: 0.0207 acc: 0.9730\n","20m 38s (- 5m 9s) (60000 80%) loss: 0.0153 acc: 0.9640\n","20m 59s (- 4m 48s) (61000 81%) loss: 0.0182 acc: 0.9710\n","21m 20s (- 4m 28s) (62000 82%) loss: 0.0115 acc: 0.9710\n","21m 40s (- 4m 7s) (63000 84%) loss: 0.0072 acc: 0.9770\n","22m 1s (- 3m 47s) (64000 85%) loss: 0.0170 acc: 0.9700\n","22m 21s (- 3m 26s) (65000 86%) loss: 0.0151 acc: 0.9610\n","22m 42s (- 3m 5s) (66000 88%) loss: 0.0079 acc: 0.9770\n","23m 2s (- 2m 45s) (67000 89%) loss: 0.0086 acc: 0.9790\n","23m 24s (- 2m 24s) (68000 90%) loss: 0.0161 acc: 0.9740\n","23m 44s (- 2m 3s) (69000 92%) loss: 0.0216 acc: 0.9690\n","24m 5s (- 1m 43s) (70000 93%) loss: 0.0148 acc: 0.9790\n","24m 26s (- 1m 22s) (71000 94%) loss: 0.0083 acc: 0.9710\n","24m 46s (- 1m 1s) (72000 96%) loss: 0.0076 acc: 0.9860\n","25m 7s (- 0m 41s) (73000 97%) loss: 0.0094 acc: 0.9870\n","25m 27s (- 0m 20s) (74000 98%) loss: 0.0084 acc: 0.9760\n","25m 47s (- 0m 0s) (75000 100%) loss: 0.0289 acc: 0.9700\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 7706/7706 [00:53<00:00, 145.27it/s]\n"]},{"output_type":"stream","name":"stdout","text":["0m 24s (- 30m 2s) (1000 1%) loss: 1.0948 acc: 0.0880\n","0m 44s (- 26m 57s) (2000 2%) loss: 0.6956 acc: 0.1310\n","1m 4s (- 25m 55s) (3000 4%) loss: 0.5603 acc: 0.1570\n","1m 24s (- 25m 6s) (4000 5%) loss: 0.4596 acc: 0.2170\n","1m 44s (- 24m 29s) (5000 6%) loss: 0.4144 acc: 0.2720\n","2m 5s (- 24m 1s) (6000 8%) loss: 0.3778 acc: 0.3090\n","2m 26s (- 23m 41s) (7000 9%) loss: 0.3287 acc: 0.3390\n","2m 46s (- 23m 15s) (8000 10%) loss: 0.3045 acc: 0.4150\n","3m 7s (- 22m 54s) (9000 12%) loss: 0.2813 acc: 0.4340\n","3m 27s (- 22m 30s) (10000 13%) loss: 0.2416 acc: 0.5070\n","3m 48s (- 22m 6s) (11000 14%) loss: 0.1693 acc: 0.5670\n","4m 7s (- 21m 41s) (12000 16%) loss: 0.1832 acc: 0.5900\n","4m 28s (- 21m 19s) (13000 17%) loss: 0.1545 acc: 0.6150\n","4m 48s (- 20m 56s) (14000 18%) loss: 0.1543 acc: 0.6390\n","5m 9s (- 20m 36s) (15000 20%) loss: 0.1363 acc: 0.6310\n","5m 30s (- 20m 18s) (16000 21%) loss: 0.1038 acc: 0.7130\n","5m 51s (- 19m 57s) (17000 22%) loss: 0.1104 acc: 0.7270\n","6m 11s (- 19m 35s) (18000 24%) loss: 0.0885 acc: 0.7590\n","6m 31s (- 19m 13s) (19000 25%) loss: 0.0915 acc: 0.7720\n","6m 51s (- 18m 51s) (20000 26%) loss: 0.0791 acc: 0.8000\n","7m 12s (- 18m 31s) (21000 28%) loss: 0.0857 acc: 0.7760\n","7m 32s (- 18m 9s) (22000 29%) loss: 0.0650 acc: 0.8030\n","7m 52s (- 17m 47s) (23000 30%) loss: 0.0569 acc: 0.8370\n","8m 13s (- 17m 29s) (24000 32%) loss: 0.0532 acc: 0.8480\n","8m 34s (- 17m 9s) (25000 33%) loss: 0.0478 acc: 0.8530\n","8m 54s (- 16m 48s) (26000 34%) loss: 0.0461 acc: 0.8710\n","9m 15s (- 16m 27s) (27000 36%) loss: 0.0374 acc: 0.8580\n","9m 36s (- 16m 7s) (28000 37%) loss: 0.0288 acc: 0.8910\n","9m 56s (- 15m 46s) (29000 38%) loss: 0.0364 acc: 0.8740\n","10m 17s (- 15m 25s) (30000 40%) loss: 0.0362 acc: 0.8980\n","10m 37s (- 15m 5s) (31000 41%) loss: 0.0325 acc: 0.8960\n","10m 58s (- 14m 44s) (32000 42%) loss: 0.0220 acc: 0.9250\n","11m 19s (- 14m 25s) (33000 44%) loss: 0.0289 acc: 0.9010\n","11m 40s (- 14m 5s) (34000 45%) loss: 0.0224 acc: 0.9110\n","12m 0s (- 13m 43s) (35000 46%) loss: 0.0214 acc: 0.9210\n","12m 20s (- 13m 22s) (36000 48%) loss: 0.0516 acc: 0.8950\n","12m 41s (- 13m 1s) (37000 49%) loss: 0.0589 acc: 0.8760\n","13m 1s (- 12m 41s) (38000 50%) loss: 0.0307 acc: 0.9090\n","13m 22s (- 12m 20s) (39000 52%) loss: 0.0255 acc: 0.9320\n","13m 42s (- 11m 59s) (40000 53%) loss: 0.0178 acc: 0.9410\n","14m 4s (- 11m 40s) (41000 54%) loss: 0.0238 acc: 0.9150\n","14m 24s (- 11m 19s) (42000 56%) loss: 0.0421 acc: 0.9150\n","14m 44s (- 10m 58s) (43000 57%) loss: 0.0284 acc: 0.9120\n","15m 5s (- 10m 37s) (44000 58%) loss: 0.0155 acc: 0.9380\n","15m 25s (- 10m 17s) (45000 60%) loss: 0.0162 acc: 0.9430\n","15m 46s (- 9m 56s) (46000 61%) loss: 0.0261 acc: 0.9300\n","16m 7s (- 9m 36s) (47000 62%) loss: 0.0370 acc: 0.9310\n","16m 27s (- 9m 15s) (48000 64%) loss: 0.0224 acc: 0.9500\n","16m 47s (- 8m 54s) (49000 65%) loss: 0.0224 acc: 0.9560\n","17m 9s (- 8m 34s) (50000 66%) loss: 0.0320 acc: 0.9450\n","17m 29s (- 8m 13s) (51000 68%) loss: 0.0089 acc: 0.9620\n","17m 49s (- 7m 53s) (52000 69%) loss: 0.0296 acc: 0.9280\n","18m 10s (- 7m 32s) (53000 70%) loss: 0.0232 acc: 0.9440\n","18m 30s (- 7m 11s) (54000 72%) loss: 0.0122 acc: 0.9590\n","18m 51s (- 6m 51s) (55000 73%) loss: 0.0172 acc: 0.9630\n","19m 11s (- 6m 30s) (56000 74%) loss: 0.0143 acc: 0.9630\n","19m 31s (- 6m 9s) (57000 76%) loss: 0.0158 acc: 0.9560\n","19m 52s (- 5m 49s) (58000 77%) loss: 0.0189 acc: 0.9490\n","20m 12s (- 5m 28s) (59000 78%) loss: 0.0070 acc: 0.9600\n","20m 33s (- 5m 8s) (60000 80%) loss: 0.0347 acc: 0.9600\n","20m 53s (- 4m 47s) (61000 81%) loss: 0.0147 acc: 0.9700\n","21m 13s (- 4m 27s) (62000 82%) loss: 0.0083 acc: 0.9750\n","21m 34s (- 4m 6s) (63000 84%) loss: 0.0131 acc: 0.9700\n","21m 54s (- 3m 45s) (64000 85%) loss: 0.0101 acc: 0.9750\n","22m 14s (- 3m 25s) (65000 86%) loss: 0.0321 acc: 0.9660\n","22m 35s (- 3m 4s) (66000 88%) loss: 0.0056 acc: 0.9730\n","22m 56s (- 2m 44s) (67000 89%) loss: 0.0045 acc: 0.9780\n","23m 17s (- 2m 23s) (68000 90%) loss: 0.0116 acc: 0.9680\n","23m 37s (- 2m 3s) (69000 92%) loss: 0.0045 acc: 0.9760\n","23m 57s (- 1m 42s) (70000 93%) loss: 0.0031 acc: 0.9910\n","24m 18s (- 1m 22s) (71000 94%) loss: 0.0060 acc: 0.9760\n","24m 38s (- 1m 1s) (72000 96%) loss: 0.0320 acc: 0.9610\n","24m 58s (- 0m 41s) (73000 97%) loss: 0.0206 acc: 0.9740\n","25m 19s (- 0m 20s) (74000 98%) loss: 0.0232 acc: 0.9710\n","25m 40s (- 0m 0s) (75000 100%) loss: 0.0117 acc: 0.9770\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 7706/7706 [00:51<00:00, 150.33it/s]\n"]},{"output_type":"stream","name":"stdout","text":["0m 24s (- 30m 15s) (1000 1%) loss: 1.1323 acc: 0.0780\n","0m 44s (- 26m 56s) (2000 2%) loss: 0.7319 acc: 0.1160\n","1m 4s (- 25m 52s) (3000 4%) loss: 0.5637 acc: 0.1610\n","1m 24s (- 25m 5s) (4000 5%) loss: 0.4557 acc: 0.2120\n","1m 45s (- 24m 39s) (5000 6%) loss: 0.3874 acc: 0.2610\n","2m 6s (- 24m 14s) (6000 8%) loss: 0.3566 acc: 0.3260\n","2m 26s (- 23m 45s) (7000 9%) loss: 0.3190 acc: 0.3560\n","2m 46s (- 23m 17s) (8000 10%) loss: 0.2946 acc: 0.4030\n","3m 7s (- 22m 54s) (9000 12%) loss: 0.2737 acc: 0.4500\n","3m 27s (- 22m 28s) (10000 13%) loss: 0.2820 acc: 0.4470\n","3m 47s (- 22m 6s) (11000 14%) loss: 0.2033 acc: 0.5440\n","4m 8s (- 21m 43s) (12000 16%) loss: 0.2295 acc: 0.5610\n","4m 28s (- 21m 22s) (13000 17%) loss: 0.1675 acc: 0.6230\n","4m 49s (- 20m 59s) (14000 18%) loss: 0.1532 acc: 0.6610\n","5m 10s (- 20m 42s) (15000 20%) loss: 0.1288 acc: 0.7050\n","5m 30s (- 20m 18s) (16000 21%) loss: 0.1209 acc: 0.7540\n","5m 50s (- 19m 56s) (17000 22%) loss: 0.0910 acc: 0.7550\n","6m 11s (- 19m 35s) (18000 24%) loss: 0.0884 acc: 0.7430\n","6m 31s (- 19m 13s) (19000 25%) loss: 0.0717 acc: 0.7770\n","6m 51s (- 18m 51s) (20000 26%) loss: 0.0864 acc: 0.7820\n","7m 12s (- 18m 31s) (21000 28%) loss: 0.0775 acc: 0.7970\n","7m 32s (- 18m 9s) (22000 29%) loss: 0.0597 acc: 0.8150\n","7m 53s (- 17m 49s) (23000 30%) loss: 0.0675 acc: 0.8230\n","8m 14s (- 17m 30s) (24000 32%) loss: 0.0714 acc: 0.8180\n","8m 35s (- 17m 10s) (25000 33%) loss: 0.0681 acc: 0.8320\n","8m 55s (- 16m 49s) (26000 34%) loss: 0.0447 acc: 0.8550\n","9m 16s (- 16m 28s) (27000 36%) loss: 0.0753 acc: 0.8490\n","9m 36s (- 16m 7s) (28000 37%) loss: 0.0515 acc: 0.8530\n","9m 57s (- 15m 46s) (29000 38%) loss: 0.0568 acc: 0.8680\n","10m 17s (- 15m 25s) (30000 40%) loss: 0.0388 acc: 0.8900\n","10m 37s (- 15m 4s) (31000 41%) loss: 0.0407 acc: 0.8840\n","10m 58s (- 14m 45s) (32000 42%) loss: 0.0397 acc: 0.8740\n","11m 19s (- 14m 24s) (33000 44%) loss: 0.0545 acc: 0.9010\n","11m 40s (- 14m 4s) (34000 45%) loss: 0.0345 acc: 0.9040\n","12m 0s (- 13m 43s) (35000 46%) loss: 0.0333 acc: 0.9130\n","12m 21s (- 13m 22s) (36000 48%) loss: 0.0434 acc: 0.9190\n","12m 41s (- 13m 2s) (37000 49%) loss: 0.0360 acc: 0.9120\n","13m 2s (- 12m 41s) (38000 50%) loss: 0.0334 acc: 0.9310\n","13m 22s (- 12m 20s) (39000 52%) loss: 0.0477 acc: 0.9350\n","13m 42s (- 11m 59s) (40000 53%) loss: 0.0253 acc: 0.9310\n","14m 3s (- 11m 39s) (41000 54%) loss: 0.0321 acc: 0.9280\n","14m 23s (- 11m 18s) (42000 56%) loss: 0.0167 acc: 0.9540\n","14m 43s (- 10m 57s) (43000 57%) loss: 0.0166 acc: 0.9510\n","15m 4s (- 10m 36s) (44000 58%) loss: 0.0424 acc: 0.9360\n","15m 24s (- 10m 16s) (45000 60%) loss: 0.0089 acc: 0.9590\n","15m 45s (- 9m 55s) (46000 61%) loss: 0.0200 acc: 0.9470\n","16m 5s (- 9m 35s) (47000 62%) loss: 0.0180 acc: 0.9580\n","16m 26s (- 9m 14s) (48000 64%) loss: 0.0119 acc: 0.9700\n","16m 46s (- 8m 54s) (49000 65%) loss: 0.0120 acc: 0.9610\n","17m 8s (- 8m 34s) (50000 66%) loss: 0.0126 acc: 0.9760\n","17m 28s (- 8m 13s) (51000 68%) loss: 0.0252 acc: 0.9630\n","17m 49s (- 7m 52s) (52000 69%) loss: 0.0097 acc: 0.9600\n","18m 10s (- 7m 32s) (53000 70%) loss: 0.0128 acc: 0.9610\n","18m 31s (- 7m 12s) (54000 72%) loss: 0.0204 acc: 0.9730\n","18m 52s (- 6m 51s) (55000 73%) loss: 0.0062 acc: 0.9910\n","19m 12s (- 6m 30s) (56000 74%) loss: 0.0083 acc: 0.9760\n","19m 32s (- 6m 10s) (57000 76%) loss: 0.0125 acc: 0.9620\n","19m 53s (- 5m 49s) (58000 77%) loss: 0.0093 acc: 0.9680\n","20m 13s (- 5m 29s) (59000 78%) loss: 0.0111 acc: 0.9720\n","20m 34s (- 5m 8s) (60000 80%) loss: 0.0136 acc: 0.9790\n","20m 55s (- 4m 48s) (61000 81%) loss: 0.0084 acc: 0.9720\n","21m 15s (- 4m 27s) (62000 82%) loss: 0.0151 acc: 0.9730\n","21m 35s (- 4m 6s) (63000 84%) loss: 0.0239 acc: 0.9730\n","21m 56s (- 3m 46s) (64000 85%) loss: 0.0068 acc: 0.9720\n","22m 16s (- 3m 25s) (65000 86%) loss: 0.0096 acc: 0.9780\n","22m 36s (- 3m 5s) (66000 88%) loss: 0.0044 acc: 0.9790\n","22m 58s (- 2m 44s) (67000 89%) loss: 0.0076 acc: 0.9860\n","23m 19s (- 2m 24s) (68000 90%) loss: 0.0252 acc: 0.9730\n","23m 39s (- 2m 3s) (69000 92%) loss: 0.0021 acc: 0.9910\n","23m 59s (- 1m 42s) (70000 93%) loss: 0.0205 acc: 0.9690\n","24m 20s (- 1m 22s) (71000 94%) loss: 0.0043 acc: 0.9820\n","24m 41s (- 1m 1s) (72000 96%) loss: 0.0049 acc: 0.9890\n","25m 2s (- 0m 41s) (73000 97%) loss: 0.0098 acc: 0.9760\n","25m 22s (- 0m 20s) (74000 98%) loss: 0.0323 acc: 0.9530\n","25m 41s (- 0m 0s) (75000 100%) loss: 0.0209 acc: 0.9600\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 7706/7706 [01:00<00:00, 127.37it/s]\n"]},{"output_type":"stream","name":"stdout","text":["0m 24s (- 30m 29s) (1000 1%) loss: 1.0671 acc: 0.0930\n","0m 44s (- 27m 16s) (2000 2%) loss: 0.7145 acc: 0.1260\n","1m 4s (- 25m 53s) (3000 4%) loss: 0.5338 acc: 0.1770\n","1m 24s (- 25m 1s) (4000 5%) loss: 0.4341 acc: 0.2320\n","1m 44s (- 24m 21s) (5000 6%) loss: 0.4015 acc: 0.2720\n","2m 5s (- 24m 3s) (6000 8%) loss: 0.3523 acc: 0.3160\n","2m 26s (- 23m 43s) (7000 9%) loss: 0.2957 acc: 0.3880\n","2m 46s (- 23m 10s) (8000 10%) loss: 0.2574 acc: 0.4430\n","3m 6s (- 22m 44s) (9000 12%) loss: 0.2616 acc: 0.4870\n","3m 26s (- 22m 22s) (10000 13%) loss: 0.2341 acc: 0.4900\n","3m 46s (- 21m 58s) (11000 14%) loss: 0.2178 acc: 0.5600\n","4m 6s (- 21m 35s) (12000 16%) loss: 0.2017 acc: 0.5910\n","4m 26s (- 21m 10s) (13000 17%) loss: 0.1692 acc: 0.6290\n","4m 47s (- 20m 51s) (14000 18%) loss: 0.1454 acc: 0.6290\n","5m 7s (- 20m 30s) (15000 20%) loss: 0.1765 acc: 0.6100\n","5m 28s (- 20m 12s) (16000 21%) loss: 0.1195 acc: 0.6630\n","5m 49s (- 19m 52s) (17000 22%) loss: 0.1141 acc: 0.6670\n","6m 9s (- 19m 31s) (18000 24%) loss: 0.1017 acc: 0.7140\n","6m 29s (- 19m 8s) (19000 25%) loss: 0.0976 acc: 0.7210\n","6m 50s (- 18m 47s) (20000 26%) loss: 0.0882 acc: 0.7410\n","7m 11s (- 18m 28s) (21000 28%) loss: 0.0715 acc: 0.7860\n","7m 31s (- 18m 8s) (22000 29%) loss: 0.0632 acc: 0.8360\n","7m 52s (- 17m 47s) (23000 30%) loss: 0.0734 acc: 0.8440\n","8m 12s (- 17m 26s) (24000 32%) loss: 0.0625 acc: 0.8630\n","8m 33s (- 17m 7s) (25000 33%) loss: 0.0531 acc: 0.8830\n","8m 54s (- 16m 47s) (26000 34%) loss: 0.0614 acc: 0.8690\n","9m 15s (- 16m 27s) (27000 36%) loss: 0.0546 acc: 0.8580\n","9m 35s (- 16m 6s) (28000 37%) loss: 0.0364 acc: 0.8880\n","9m 55s (- 15m 44s) (29000 38%) loss: 0.0413 acc: 0.9050\n","10m 15s (- 15m 23s) (30000 40%) loss: 0.0407 acc: 0.9050\n","10m 36s (- 15m 3s) (31000 41%) loss: 0.0289 acc: 0.9170\n","10m 56s (- 14m 42s) (32000 42%) loss: 0.0396 acc: 0.9160\n","11m 17s (- 14m 21s) (33000 44%) loss: 0.0346 acc: 0.9210\n","11m 39s (- 14m 2s) (34000 45%) loss: 0.0343 acc: 0.9290\n","11m 59s (- 13m 42s) (35000 46%) loss: 0.0222 acc: 0.9420\n","12m 20s (- 13m 21s) (36000 48%) loss: 0.0262 acc: 0.9260\n","12m 40s (- 13m 1s) (37000 49%) loss: 0.0333 acc: 0.9260\n","13m 1s (- 12m 40s) (38000 50%) loss: 0.0327 acc: 0.9150\n","13m 22s (- 12m 20s) (39000 52%) loss: 0.0182 acc: 0.9530\n","13m 43s (- 12m 0s) (40000 53%) loss: 0.0409 acc: 0.9300\n","14m 3s (- 11m 39s) (41000 54%) loss: 0.0076 acc: 0.9680\n","14m 24s (- 11m 19s) (42000 56%) loss: 0.0448 acc: 0.9270\n","14m 45s (- 10m 59s) (43000 57%) loss: 0.0119 acc: 0.9580\n","15m 6s (- 10m 38s) (44000 58%) loss: 0.0318 acc: 0.9620\n","15m 26s (- 10m 17s) (45000 60%) loss: 0.0277 acc: 0.9530\n","15m 46s (- 9m 56s) (46000 61%) loss: 0.0380 acc: 0.9480\n","16m 6s (- 9m 35s) (47000 62%) loss: 0.0392 acc: 0.9410\n","16m 26s (- 9m 15s) (48000 64%) loss: 0.0249 acc: 0.9430\n","16m 47s (- 8m 54s) (49000 65%) loss: 0.0284 acc: 0.9420\n","17m 7s (- 8m 33s) (50000 66%) loss: 0.0249 acc: 0.9490\n","17m 28s (- 8m 13s) (51000 68%) loss: 0.0160 acc: 0.9680\n","17m 49s (- 7m 53s) (52000 69%) loss: 0.0256 acc: 0.9470\n","18m 10s (- 7m 32s) (53000 70%) loss: 0.0134 acc: 0.9760\n","18m 31s (- 7m 12s) (54000 72%) loss: 0.0163 acc: 0.9650\n","18m 51s (- 6m 51s) (55000 73%) loss: 0.0055 acc: 0.9820\n","19m 11s (- 6m 30s) (56000 74%) loss: 0.0271 acc: 0.9700\n","19m 31s (- 6m 10s) (57000 76%) loss: 0.0240 acc: 0.9700\n","19m 52s (- 5m 49s) (58000 77%) loss: 0.0160 acc: 0.9710\n","20m 13s (- 5m 28s) (59000 78%) loss: 0.0076 acc: 0.9810\n","20m 33s (- 5m 8s) (60000 80%) loss: 0.0167 acc: 0.9670\n","20m 54s (- 4m 47s) (61000 81%) loss: 0.0061 acc: 0.9780\n","21m 15s (- 4m 27s) (62000 82%) loss: 0.0135 acc: 0.9740\n","21m 35s (- 4m 6s) (63000 84%) loss: 0.0069 acc: 0.9780\n","21m 56s (- 3m 46s) (64000 85%) loss: 0.0041 acc: 0.9880\n","22m 17s (- 3m 25s) (65000 86%) loss: 0.0162 acc: 0.9640\n","22m 38s (- 3m 5s) (66000 88%) loss: 0.0091 acc: 0.9780\n","22m 58s (- 2m 44s) (67000 89%) loss: 0.0171 acc: 0.9790\n","23m 19s (- 2m 24s) (68000 90%) loss: 0.0037 acc: 0.9860\n","23m 39s (- 2m 3s) (69000 92%) loss: 0.0173 acc: 0.9750\n","24m 0s (- 1m 42s) (70000 93%) loss: 0.0092 acc: 0.9780\n","24m 21s (- 1m 22s) (71000 94%) loss: 0.0133 acc: 0.9740\n","24m 41s (- 1m 1s) (72000 96%) loss: 0.0309 acc: 0.9760\n","25m 1s (- 0m 41s) (73000 97%) loss: 0.0075 acc: 0.9820\n","25m 22s (- 0m 20s) (74000 98%) loss: 0.0041 acc: 0.9890\n","25m 42s (- 0m 0s) (75000 100%) loss: 0.0114 acc: 0.9790\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/Advanced NLP/Exam/utils.py:67: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n","  plt.figure()\n","/content/drive/My Drive/Advanced NLP/Exam/utils.py:68: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n","  fig, ax = plt.subplots()\n","100%|██████████| 7706/7706 [00:50<00:00, 152.43it/s]\n"]},{"output_type":"execute_result","data":{"text/plain":["([{9: 0.0, 6: 0.0, 8: 0.0, 5: 0.0, 7: 0.0, 4: 0.0, 3: 0.0, 2: 0.0},\n","  {9: 0.0, 6: 0.0, 8: 0.0, 5: 0.0, 7: 0.0, 4: 0.0, 3: 0.0, 2: 0.0},\n","  {9: 0.0,\n","   6: 0.000744047619047619,\n","   8: 0.0,\n","   5: 0.005859375,\n","   7: 0.0,\n","   4: 0.0078125,\n","   3: 0.0,\n","   2: 0.0},\n","  {9: 0.0, 6: 0.0, 8: 0.0, 5: 0.0, 7: 0.0, 4: 0.0, 3: 0.0, 2: 0.0},\n","  {9: 0.0, 6: 0.0, 8: 0.0, 5: 0.001953125, 7: 0.0, 4: 0.0, 3: 0.0, 2: 0.25},\n","  {9: 0.0, 6: 0.0, 8: 0.0, 5: 0.0, 7: 0.0, 4: 0.0, 3: 0.0, 2: 0.0},\n","  {9: 0.0, 6: 0.0, 8: 0.0, 5: 0.001953125, 7: 0.0, 4: 0.0, 3: 0.0, 2: 0.0},\n","  {9: 0.0,\n","   6: 0.000744047619047619,\n","   8: 0.0,\n","   5: 0.001953125,\n","   7: 0.0,\n","   4: 0.0,\n","   3: 0.0,\n","   2: 0.0},\n","  {9: 0.0,\n","   6: 0.004464285714285714,\n","   8: 0.0,\n","   5: 0.0078125,\n","   7: 0.0,\n","   4: 0.0078125,\n","   3: 0.0,\n","   2: 0.0},\n","  {9: 0.0, 6: 0.0, 8: 0.0, 5: 0.005859375, 7: 0.0, 4: 0.0, 3: 0.0, 2: 0.0}],\n"," [{12: 0.0,\n","   11: 0.0,\n","   15: 0.0,\n","   3: 0.0,\n","   5: 0.0,\n","   14: 0.0,\n","   22: 0.0,\n","   13: 0.0,\n","   8: 0.0,\n","   17: 0.0,\n","   10: 0.0,\n","   4: 0.0,\n","   19: 0.0,\n","   24: 0.0,\n","   27: 0.0,\n","   33: 0.0,\n","   26: 0.0,\n","   9: 0.0,\n","   32: 0.0,\n","   28: 0.0,\n","   6: 0.0,\n","   7: 0.0,\n","   18: 0.0,\n","   2: 0.0,\n","   20: 0.0,\n","   30: 0.0,\n","   16: 0.0,\n","   48: 0.0,\n","   25: 0.0,\n","   40: 0.0,\n","   21: 0.0,\n","   36: 0.0},\n","  {12: 0.0,\n","   11: 0.0,\n","   15: 0.0,\n","   3: 0.0,\n","   5: 0.0,\n","   14: 0.0,\n","   22: 0.0,\n","   13: 0.0,\n","   8: 0.0,\n","   17: 0.0,\n","   10: 0.0,\n","   4: 0.0,\n","   19: 0.0,\n","   24: 0.0,\n","   27: 0.0,\n","   33: 0.0,\n","   26: 0.0,\n","   9: 0.0,\n","   32: 0.0,\n","   28: 0.0,\n","   6: 0.0,\n","   7: 0.0,\n","   18: 0.0,\n","   2: 0.0,\n","   20: 0.0,\n","   30: 0.0,\n","   16: 0.0,\n","   48: 0.0,\n","   25: 0.0,\n","   40: 0.0,\n","   21: 0.0,\n","   36: 0.0},\n","  {12: 0.0,\n","   11: 0.0,\n","   15: 0.0,\n","   3: 0.007874015748031496,\n","   5: 0.0048543689320388345,\n","   14: 0.0,\n","   22: 0.0,\n","   13: 0.0,\n","   8: 0.0,\n","   17: 0.005,\n","   10: 0.0,\n","   4: 0.0,\n","   19: 0.0,\n","   24: 0.0,\n","   27: 0.0,\n","   33: 0.0,\n","   26: 0.0,\n","   9: 0.0,\n","   32: 0.0,\n","   28: 0.0,\n","   6: 0.0,\n","   7: 0.0026041666666666665,\n","   18: 0.0,\n","   2: 0.0,\n","   20: 0.0,\n","   30: 0.0,\n","   16: 0.0,\n","   48: 0.0,\n","   25: 0.0,\n","   40: 0.0,\n","   21: 0.0,\n","   36: 0.0},\n","  {12: 0.0,\n","   11: 0.0,\n","   15: 0.0,\n","   3: 0.0,\n","   5: 0.0,\n","   14: 0.0,\n","   22: 0.0,\n","   13: 0.0,\n","   8: 0.0,\n","   17: 0.0,\n","   10: 0.0,\n","   4: 0.0,\n","   19: 0.0,\n","   24: 0.0,\n","   27: 0.0,\n","   33: 0.0,\n","   26: 0.0,\n","   9: 0.0,\n","   32: 0.0,\n","   28: 0.0,\n","   6: 0.0,\n","   7: 0.0,\n","   18: 0.0,\n","   2: 0.0,\n","   20: 0.0,\n","   30: 0.0,\n","   16: 0.0,\n","   48: 0.0,\n","   25: 0.0,\n","   40: 0.0,\n","   21: 0.0,\n","   36: 0.0},\n","  {12: 0.0,\n","   11: 0.0,\n","   15: 0.0,\n","   3: 0.0,\n","   5: 0.0024271844660194173,\n","   14: 0.0,\n","   22: 0.0,\n","   13: 0.0,\n","   8: 0.0,\n","   17: 0.0,\n","   10: 0.0,\n","   4: 0.0,\n","   19: 0.0,\n","   24: 0.0,\n","   27: 0.0,\n","   33: 0.0,\n","   26: 0.0,\n","   9: 0.0,\n","   32: 0.0,\n","   28: 0.0,\n","   6: 0.0,\n","   7: 0.0,\n","   18: 0.0,\n","   2: 0.04,\n","   20: 0.0,\n","   30: 0.0,\n","   16: 0.0,\n","   48: 0.0,\n","   25: 0.0,\n","   40: 0.0,\n","   21: 0.0,\n","   36: 0.0},\n","  {12: 0.0,\n","   11: 0.0,\n","   15: 0.0,\n","   3: 0.0,\n","   5: 0.0,\n","   14: 0.0,\n","   22: 0.0,\n","   13: 0.0,\n","   8: 0.0,\n","   17: 0.0,\n","   10: 0.0,\n","   4: 0.0,\n","   19: 0.0,\n","   24: 0.0,\n","   27: 0.0,\n","   33: 0.0,\n","   26: 0.0,\n","   9: 0.0,\n","   32: 0.0,\n","   28: 0.0,\n","   6: 0.0,\n","   7: 0.0,\n","   18: 0.0,\n","   2: 0.0,\n","   20: 0.0,\n","   30: 0.0,\n","   16: 0.0,\n","   48: 0.0,\n","   25: 0.0,\n","   40: 0.0,\n","   21: 0.0,\n","   36: 0.0},\n","  {12: 0.0,\n","   11: 0.0,\n","   15: 0.0,\n","   3: 0.0,\n","   5: 0.0,\n","   14: 0.0,\n","   22: 0.0,\n","   13: 0.0,\n","   8: 0.0,\n","   17: 0.0,\n","   10: 0.0,\n","   4: 0.0,\n","   19: 0.0,\n","   24: 0.0,\n","   27: 0.0,\n","   33: 0.0,\n","   26: 0.0,\n","   9: 0.002109704641350211,\n","   32: 0.0,\n","   28: 0.0,\n","   6: 0.0,\n","   7: 0.0,\n","   18: 0.0,\n","   2: 0.0,\n","   20: 0.0,\n","   30: 0.0,\n","   16: 0.0,\n","   48: 0.0,\n","   25: 0.0,\n","   40: 0.0,\n","   21: 0.0,\n","   36: 0.0},\n","  {12: 0.0,\n","   11: 0.0,\n","   15: 0.0,\n","   3: 0.0,\n","   5: 0.0,\n","   14: 0.0,\n","   22: 0.0,\n","   13: 0.0,\n","   8: 0.0,\n","   17: 0.0,\n","   10: 0.0,\n","   4: 0.0,\n","   19: 0.0,\n","   24: 0.0,\n","   27: 0.0,\n","   33: 0.0,\n","   26: 0.0,\n","   9: 0.002109704641350211,\n","   32: 0.0,\n","   28: 0.0,\n","   6: 0.0,\n","   7: 0.0,\n","   18: 0.0,\n","   2: 0.0,\n","   20: 0.0,\n","   30: 0.0,\n","   16: 0.0,\n","   48: 0.0,\n","   25: 0.005434782608695652,\n","   40: 0.0,\n","   21: 0.0,\n","   36: 0.0},\n","  {12: 0.0,\n","   11: 0.0,\n","   15: 0.0,\n","   3: 0.0,\n","   5: 0.0,\n","   14: 0.0,\n","   22: 0.0,\n","   13: 0.006578947368421052,\n","   8: 0.0,\n","   17: 0.005,\n","   10: 0.0033333333333333335,\n","   4: 0.003424657534246575,\n","   19: 0.0,\n","   24: 0.0,\n","   27: 0.0,\n","   33: 0.0,\n","   26: 0.0,\n","   9: 0.004219409282700422,\n","   32: 0.0,\n","   28: 0.0,\n","   6: 0.0,\n","   7: 0.0078125,\n","   18: 0.0,\n","   2: 0.0,\n","   20: 0.0,\n","   30: 0.0,\n","   16: 0.0,\n","   48: 0.0,\n","   25: 0.005434782608695652,\n","   40: 0.0,\n","   21: 0.0,\n","   36: 0.0},\n","  {12: 0.0,\n","   11: 0.0,\n","   15: 0.0,\n","   3: 0.0,\n","   5: 0.0024271844660194173,\n","   14: 0.0,\n","   22: 0.0,\n","   13: 0.0,\n","   8: 0.0,\n","   17: 0.0,\n","   10: 0.0,\n","   4: 0.003424657534246575,\n","   19: 0.0,\n","   24: 0.0,\n","   27: 0.0,\n","   33: 0.0,\n","   26: 0.0,\n","   9: 0.0,\n","   32: 0.0,\n","   28: 0.0,\n","   6: 0.0,\n","   7: 0.0026041666666666665,\n","   18: 0.0,\n","   2: 0.0,\n","   20: 0.0,\n","   30: 0.0,\n","   16: 0.0,\n","   48: 0.0,\n","   25: 0.0,\n","   40: 0.0,\n","   21: 0.0,\n","   36: 0.0}],\n"," [0.0,\n","  0.0,\n","  0.0006488450558006748,\n","  0.0,\n","  0.0002595380223202699,\n","  0.0,\n","  0.00012976901116013495,\n","  0.0002595380223202699,\n","  0.0014274591227614846,\n","  0.0003893070334804049],\n"," [0.979, 0.987, 0.987, 0.977, 0.984, 0.973, 0.97, 0.977, 0.96, 0.979])"]},"metadata":{},"execution_count":7}],"source":["# overall best model: LSTM\n","main_run(hidden_size=200, num_layers=2, dropout=0.5, num_iter=75000, num_runs=10, model='lstm', attention=False, experiment =\"3b2\")"],"id":"dc8ffbfb"},{"cell_type":"code","execution_count":null,"metadata":{"id":"Gi0ycgqeTnje"},"outputs":[],"source":[],"id":"Gi0ycgqeTnje"}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.12"}},"nbformat":4,"nbformat_minor":5}