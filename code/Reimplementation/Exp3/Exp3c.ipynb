{"cells":[{"cell_type":"code","execution_count":null,"id":"d35be239","metadata":{"id":"d35be239"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive/')\n","\n","\n","import os\n","os.chdir(\"drive/My Drive/Advanced NLP/Exam\")\n","\n","import pickle\n","import random\n","import time\n","from collections import Counter, defaultdict\n","\n","import matplotlib.pyplot as plt\n","import matplotlib.ticker as ticker\n","import torch\n","import torch.nn as nn\n","from torch import optim\n","\n","plt.switch_backend('agg')\n","import numpy as np\n","from tqdm import tqdm\n","\n","from models import EncoderGRU, AttnDecoderGRU, EncoderLSTM, DecoderLSTM, AttnDecoderLSTM\n","from utils import Lang, tensorsFromPair, timeSince, showPlot\n"]},{"cell_type":"code","source":["\n","SOS_token = 0\n","EOS_token = 1\n","\n","command_le = Lang('command')\n","action_le = Lang('action')\n","\n","class Format:\n","    def __init__(self, name):\n","        self.name = name\n","        self.word2index = {}\n","        self.index2word = {SOS_token: \"SOS\", EOS_token: \"EOS\"}\n","        self.n_words = 2  # Count SOS and EOS\n","\n","    def addSentence(self, sentence):\n","        for word in sentence:\n","            self.addWord(word)\n","\n","    def addWord(self, word):\n","        if word not in self.word2index:\n","            self.word2index[word] = self.n_words\n","            self.index2word[self.n_words] = word\n","            self.n_words += 1\n","            \n","def readFile(filename):\n","    print(\"Reading lines...\")\n","\n","    # Read the file and split into lines\n","    lines = open('SCAN-master/%s.txt' % filename, encoding='utf-8').read().strip().split('\\n')\n","\n","    pairs = [s[4:].split(' OUT: ') for s in lines]\n","\n","    input_lang = Format(\"input\")\n","    output_lang = Format(\"output\")\n","\n","    return input_lang, output_lang, pairs\n","\n","def prepareData(filename):\n","    input_lang, output_lang, pairs = readFile(filename)\n","    print(\"Read %s sentence pairs\" % len(pairs))\n","\n","    print(\"Counting words...\")\n","    for pair in pairs:\n","        input_lang.addSentence(pair[0])\n","        output_lang.addSentence(pair[1])\n","    print(\"Counted words:\")\n","    print(input_lang.name, input_lang.n_words)\n","    print(output_lang.name, output_lang.n_words)\n","    return input_lang, output_lang, pairs\n","\n","\n","def indexesFromSentence(lang, sentence):\n","    return [lang.word2index[word] for word in sentence]# .split(' ')\n","\n","\n","def tensorFromSentence(lang, sentence):\n","    indexes = indexesFromSentence(lang, sentence)\n","    indexes.append(EOS_token)\n","    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n","\n","def tensorsFromPair(pair, input_lang, output_lang):\n","    input_tensor = tensorFromSentence(input_lang, pair[0])\n","    target_tensor = tensorFromSentence(output_lang, pair[1])\n","    return (input_tensor, target_tensor)\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","dataset_path = '../SCAN-master'\n","task_name = 'add_prim'  # or 'length'\n","primitive = 'jump'\n","\n","train_file_name = '{}_split/tasks_{}_{}.txt'.format(task_name, 'train', 'addprim'+'_'+primitive)\n","test_file_name = '{}_split/tasks_{}_{}.txt'.format(task_name, 'test', 'addprim'+'_'+primitive)\n","train_file_path = os.path.join(dataset_path, train_file_name)\n","test_file_path = os.path.join(dataset_path, test_file_name)\n","\n","# train_file_path, test_file_path\n","\n","SOS_token = 0\n","EOS_token = 1\n","\n","command_le = Lang('command')\n","action_le = Lang('action')\n","\n","\n","def dataloader(path):\n","    with open(path, 'r') as f:\n","        dataset = f.readlines()\n","\n","    def preprocess_data(line):\n","        line = line.strip().split()\n","        split_index = line.index('OUT:')\n","        inp = line[1: split_index]\n","        outp = line[split_index + 1:]\n","        command_le.addSentence(inp)\n","        action_le.addSentence(outp)\n","        return [inp, outp]\n","\n","    pairs = list(map(preprocess_data, dataset))\n","    input_commands, output_actions = np.transpose(pairs).tolist()\n","    return input_commands, output_actions, pairs\n","\n","\n","commands_train, actions_train, pairs_train = dataloader(train_file_path)\n","commands_test, actions_test, pairs_test = dataloader(test_file_path)\n","\n","MAX_LENGTH = max([len(action) for action in actions_test]) + 1\n","\n","def indexesFromSentence(lang, sentence):\n","    return [lang.word2index[word] for word in sentence] # .split(' ')\n","\n","\n","def tensorFromSentence(lang, sentence):\n","    indexes = indexesFromSentence(lang, sentence)\n","    indexes.append(EOS_token)\n","    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n","\n","\n","def tensorsFromPair(pair, command_le, action_le):\n","    input_tensor = tensorFromSentence(command_le, pair[0])\n","    target_tensor = tensorFromSentence(action_le, pair[1])\n","    return (input_tensor, target_tensor)\n","\n","\n","def evaluate(encoder, decoder, pair, model='gru', attention=True, max_length=MAX_LENGTH, device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")):\n","    with torch.no_grad():\n","        input_tensor, target_tensor = tensorsFromPair(pair, command_le, action_le)\n","        input_length = input_tensor.size()[0]\n","        encoder_hidden = encoder.initHidden()\n","\n","        encoder_hiddens = torch.zeros(input_length, encoder.hidden_size, device=device)\n","\n","        for ei in range(input_length):\n","            encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n","            \n","            if attention:\n","                if model == 'lstm':\n","                    encoder_hiddens[ei] += encoder_hidden[0][0,0]\n","                elif model == 'gru':\n","                    encoder_hiddens[ei] += encoder_hidden[0,0]\n","\n","\n","        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n","\n","        decoder_hidden = encoder_hidden\n","\n","        decoded_words = []\n","        decoder_attentions = torch.zeros(max_length, input_length)\n","\n","        for di in range(max_length):\n","            if attention:\n","                decoder_output, decoder_hidden, decoder_attention = decoder(\n","                    decoder_input, decoder_hidden, encoder_hiddens)\n","                decoder_attentions[di] = decoder_attention.squeeze().data.to(device)\n","            else:\n","                decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n","            topv, topi = decoder_output.data.topk(1)\n","            if topi.item() == EOS_token:\n","                decoded_words.append('<EOS>')\n","                break\n","            else:\n","                decoded_words.append(action_le.index2word[topi.item()])\n","\n","            decoder_input = topi.squeeze().detach()\n","\n","        return decoded_words, decoder_attentions[:di+1]\n","\n","\n","def evaluate_search_failure(encoder, decoder, pair, max_length=MAX_LENGTH, attention=False):\n","    with torch.no_grad():\n","        input_tensor, target_tensor = tensorsFromPair(pair, command_le, action_le)\n","        target_output = pair[1]\n","        input_length = input_tensor.size()[0]\n","        target_length = target_tensor.size()[0]\n","        encoder_hidden = encoder.initHidden()\n","\n","        encoder_hiddens = torch.zeros(input_length, encoder.hidden_size, device=device)\n","\n","        for ei in range(input_length):\n","            encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n","            encoder_hiddens[ei] += encoder_output[0,0]\n","\n","        decoded_words_tf = []\n","        decoded_words_sg = []\n","        cumul_prob_tf = torch.tensor(0, dtype=torch.float).to(device)\n","        cumul_prob_sg = torch.tensor(0, dtype=torch.float).to(device)\n","        \n","        # Teacher forcing evaluation\n","        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n","\n","        decoder_hidden = encoder_hidden\n","        \n","        for di in range(target_length):\n","            if attention:\n","                decoder_output, decoder_hidden, decoder_attention = decoder(\n","                    decoder_input, decoder_hidden, encoder_hiddens)\n","            else:\n","                decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n","            \n","            topv, topi = decoder_output.data.topk(1)\n","            cumul_prob_tf += topv.squeeze().item()\n","            \n","            if topi.item() == EOS_token:\n","                break\n","            else:\n","                decoded_words_tf.append(action_le.index2word[topi.item()])\n","                \n","            decoder_input = target_tensor[di]\n","        \n","        # Self generated evaluation\n","        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n","\n","        decoder_hidden = encoder_hidden\n","        \n","        for di in range(max_length):\n","            decoder_output, decoder_hidden, decoder_attention = decoder(\n","                    decoder_input, decoder_hidden, encoder_hiddens)\n","            \n","            topv, topi = decoder_output.data.topk(1)\n","            cumul_prob_sg += topv.squeeze().item()\n","            \n","            if topi.item() == EOS_token:\n","                break\n","            else:\n","                decoded_words_sg.append(action_le.index2word[topi.item()])\n","                \n","            decoder_input = topi.squeeze()\n","        \n","        both_wrong = (decoded_words_tf != target_output) and (decoded_words_sg != target_output)\n","        return both_wrong, cumul_prob_sg.item(), cumul_prob_tf.item()\n","\n","\n","def evaluate_model_search_failure(encoder, decoder, test_pairs, attention=False):\n","    probs_sg = []\n","    probs_tf = []\n","    \n","    for pair in tqdm(test_pairs):\n","        both_wrong, sg_prob, tf_prob = evaluate_search_failure(encoder, decoder, pair, attention)\n","        \n","        if both_wrong:\n","            probs_sg.append(sg_prob)\n","            probs_tf.append(tf_prob)\n","            \n","    return probs_sg, probs_tf"],"metadata":{"id":"8CP_-oteeQrQ","executionInfo":{"status":"ok","timestamp":1674038590337,"user_tz":-60,"elapsed":531,"user":{"displayName":"Marie Mortensen","userId":"14481540874930151406"}}},"id":"8CP_-oteeQrQ","execution_count":10,"outputs":[]},{"cell_type":"code","source":["# Print errors for turn left and jump\n","# Overall-best model\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","input_size = command_le.n_words\n","output_size = action_le.n_words\n","\n","best_encoder_lstm_turn = EncoderLSTM(input_size=input_size, hidden_size=200, dropout=0.5, num_layers=2)\n","best_decoder_lstm_turn = DecoderLSTM(hidden_size=200, output_size=output_size, dropout=0.5, num_layers=2)\n","\n","best_encoder_lstm_turn.load_state_dict(torch.load(f\"encoder_3a2_lstm_False.pt\"))\n","best_decoder_lstm_turn.load_state_dict(torch.load(f\"decoder3a2_lstm_False.pt\"))\n","\n","best_encoder_lstm_jump = EncoderLSTM(input_size=input_size, hidden_size=200, dropout=0.5, num_layers=2)\n","best_decoder_lstm_jump = DecoderLSTM(hidden_size=200, output_size=output_size, dropout=0.5, num_layers=2)\n","\n","best_encoder_lstm_jump.load_state_dict(torch.load(f\"encoder_3b2_lstm_False.pt\"))\n","best_decoder_lstm_jump.load_state_dict(torch.load(f\"decoder3b2_lstm_False.pt\"))\n","\n"],"metadata":{"id":"AmECKCvxdDBL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1674038380217,"user_tz":-60,"elapsed":7090,"user":{"displayName":"Marie Mortensen","userId":"14481540874930151406"}},"outputId":"f6a2223a-1663-4344-f8b8-9fc8302258df"},"id":"AmECKCvxdDBL","execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":2}]},{"cell_type":"code","source":["task = \"turn_left\"\n","\n","dataset_path = '../SCAN-master/add_prim_split/'\n","\n","train_file_name = f'tasks_train_addprim_{task}.txt'\n","test_file_name = f'tasks_test_addprim_{task}.txt'\n","\n","train_file_path = os.path.join(dataset_path, train_file_name)\n","test_file_path = os.path.join(dataset_path, test_file_name)\n","\n","command_le = Format('input')\n","action_le = Format('output')\n","\n","commands_train, actions_train, pairs_train = dataloader(train_file_path)\n","commands_test, actions_test, pairs_test = dataloader(test_file_path)\n","\n","total = 0\n","turn_left = 0\n","turn_left_thrice = 0 \n","turn_left_twice = 0\n","\n","counts = {\"turn left\":0, \"turn left thrice\":0}\n","counts_testset = {}\n","errors = []\n","\n","best_encoder_lstm_turn.to(device)\n","best_decoder_lstm_turn.to(device)\n","\n","for i in range(len(pairs_test)):\n","        counts_testset[\" \".join(pairs_test[i][0])] = 0\n","        counts[\" \".join(pairs_test[i][0])] = 0\n","        preds, attentions = evaluate(best_encoder_lstm_turn, best_decoder_lstm_turn, pairs_test[i], model = 'lstm', attention=False)\n","        preds = preds[:-1]\n","        target_output = pairs_test[i][1]\n","        if preds != target_output:\n","            if \" \".join(pairs_test[i][0]).startswith(\"turn left thrice\"):\n","                counts[\"turn left thrice\"] = counts.get(\"turn left thrice\", 0) + 1\n","            elif \" \".join(pairs_test[i][0]).startswith(\"turn left\"):\n","                counts[\"turn left\"] = counts.get(\"turn left\", 0) + 1\n","            errors.append(\" \".join(pairs_test[i][0]))\n","            total+=1\n","            counts[\" \".join(pairs_test[i][0])] = counts.get(\" \".join(pairs_test[i][0]), 0) + 1\n","\n","        counts_testset[\" \".join(pairs_test[i][0])] = counts_testset.get(\" \".join(pairs_test[i][0]), 0) + 1\n","\n","probs_sg, probs_tf = evaluate_model_search_failure(best_encoder_lstm_turn, best_decoder_lstm_turn, pairs_test, attention=False)"],"metadata":{"id":"aKyN0gVXecoV"},"id":"aKyN0gVXecoV","execution_count":null,"outputs":[]},{"cell_type":"code","source":["task = \"jump\"\n","\n","dataset_path = '../SCAN-master/add_prim_split/'\n","\n","train_file_name = f'tasks_train_addprim_{task}.txt'\n","test_file_name = f'tasks_test_addprim_{task}.txt'\n","\n","train_file_path = os.path.join(dataset_path, train_file_name)\n","test_file_path = os.path.join(dataset_path, test_file_name)\n","\n","command_le = Format('input')\n","action_le = Format('output')\n","\n","commands_train, actions_train, pairs_train = dataloader(train_file_path)\n","commands_test, actions_test, pairs_test = dataloader(test_file_path)\n","\n","for i in range(len(pairs_test)):\n","        preds, attentions = evaluate(best_encoder_lstm_jump.to(device), best_decoder_lstm_jump.to(device), pairs_test[i], model=\"lstm\", attention=False)\n","        preds = preds[:-1]\n","        target_output = pairs_test[i][1]\n","        if preds == target_output:\n","            print(pairs_test[i][0])\n","\n"],"metadata":{"id":"DaeEB2hNejiv"},"id":"DaeEB2hNejiv","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Testing for search errors\n","task = \"jump\"\n","\n","dataset_path = '../SCAN-master/add_prim_split/'\n","\n","train_file_name = f'tasks_train_addprim_{task}.txt'\n","test_file_name = f'tasks_test_addprim_{task}.txt'\n","\n","train_file_path = os.path.join(dataset_path, train_file_name)\n","test_file_path = os.path.join(dataset_path, test_file_name)\n","\n","command_le = Format('input')\n","action_le = Format('output')\n","\n","def dataloader(path):\n","    with open(path, 'r') as f:\n","        dataset = f.readlines()\n","\n","    def preprocess_data(line):\n","        line = line.strip().split()\n","        split_index = line.index('OUT:')\n","        inp = line[1: split_index]\n","        outp = line[split_index + 1:]\n","        command_le.addSentence(inp)\n","        action_le.addSentence(outp)\n","        return [inp, outp]\n","\n","    pairs = list(map(preprocess_data, dataset))\n","    input_commands, output_actions = np.transpose(pairs).tolist()\n","    return input_commands, output_actions, pairs\n","\n","\n","commands_train, actions_train, pairs_train = dataloader(train_file_path)\n","commands_test, actions_test, pairs_test = dataloader(test_file_path)\n","\n","input_size = command_le.n_words\n","output_size = action_le.n_words\n","\n","probs_sg, probs_tf = evaluate_model_search_failure(best_encoder_lstm_jump, best_decoder_lstm_jump, pairs_test, attention=False)"],"metadata":{"id":"lzU9EHqTe5-L","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1674038822596,"user_tz":-60,"elapsed":63179,"user":{"displayName":"Marie Mortensen","userId":"14481540874930151406"}},"outputId":"f1310d57-4304-40dc-fd49-e2ffb8b28377"},"id":"lzU9EHqTe5-L","execution_count":14,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 7706/7706 [01:02<00:00, 123.15it/s]\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"bnIakwxvfE2Z"},"id":"bnIakwxvfE2Z","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.12"},"colab":{"provenance":[]},"accelerator":"GPU","gpuClass":"standard"},"nbformat":4,"nbformat_minor":5}