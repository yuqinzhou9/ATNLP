{"cells":[{"cell_type":"code","execution_count":2,"id":"d35be239","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d35be239","executionInfo":{"status":"ok","timestamp":1674039535563,"user_tz":-60,"elapsed":118491,"user":{"displayName":"Marie Mortensen","userId":"14481540874930151406"}},"outputId":"6c332772-3e2d-4dbb-c2c1-60176339036e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive/')\n","\n","\n","import os\n","os.chdir(\"drive/My Drive/Advanced NLP/Exam\")\n","\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import random\n","import torch.nn.functional as F\n","from torch import optim\n","from sklearn.preprocessing import LabelEncoder\n","import matplotlib.pyplot as plt\n","plt.switch_backend('agg')\n","import matplotlib.ticker as ticker\n","from tqdm import tqdm\n","import numpy as np\n","%matplotlib inline \n","from torch.nn.utils import clip_grad_value_\n","\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","source":["SOS_token = 0\n","EOS_token = 1\n","\n","class Format:\n","    def __init__(self, name):\n","        self.name = name\n","        self.word2index = {}\n","        self.index2word = {SOS_token: \"SOS\", EOS_token: \"EOS\"}\n","        self.n_words = 2  # Count SOS and EOS\n","\n","    def addSentence(self, sentence):\n","        for word in sentence.split(' '):\n","            self.addWord(word)\n","\n","    def addWord(self, word):\n","        if word not in self.word2index:\n","            self.word2index[word] = self.n_words\n","            self.index2word[self.n_words] = word\n","            self.n_words += 1\n","            \n","def readFile(filename):\n","    print(\"Reading lines...\")\n","\n","    # Read the file and split into lines\n","    lines = open('../SCAN-master/%s.txt' % filename, encoding='utf-8').read().strip().split('\\n')\n","\n","    pairs = [s[4:].split(' OUT: ') for s in lines]\n","\n","    input_lang = Format(\"input\")\n","    output_lang = Format(\"output\")\n","\n","    return input_lang, output_lang, pairs\n","\n","def prepareData(filename):\n","    input_lang, output_lang, pairs = readFile(filename)\n","    print(\"Read %s sentence pairs\" % len(pairs))\n","\n","    print(\"Counting words...\")\n","    for pair in pairs:\n","        input_lang.addSentence(pair[0])\n","        output_lang.addSentence(pair[1])\n","    print(\"Counted words:\")\n","    print(input_lang.name, input_lang.n_words)\n","    print(output_lang.name, output_lang.n_words)\n","    return input_lang, output_lang, pairs\n","\n","\n","def indexesFromSentence(lang, sentence):\n","    return [lang.word2index[word] for word in sentence.split(' ')]\n","\n","\n","def tensorFromSentence(lang, sentence):\n","    indexes = indexesFromSentence(lang, sentence)\n","    indexes.append(EOS_token)\n","    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n","\n","def tensorsFromPair(pair):\n","    input_tensor = tensorFromSentence(input_lang, pair[0])\n","    target_tensor = tensorFromSentence(output_lang, pair[1])\n","    return (input_tensor, target_tensor)\n"," \n","class EncoderLSTM(nn.Module):\n","    def __init__(self, input_size, hidden_size, dropout_prob=0.1, number_of_layers=1):\n","        super(EncoderLSTM, self).__init__()\n","        self.number_of_layers = number_of_layers\n","        self.hidden_size = hidden_size\n","\n","        self.embedding = nn.Embedding(input_size, hidden_size)\n","        self.lstm = nn.LSTM(hidden_size, hidden_size, num_layers=number_of_layers, dropout=dropout_prob)\n","        self.dropout = nn.Dropout(dropout_prob)\n","\n","    def forward(self, input, hidden):\n","        embedded = (self.dropout(self.embedding(input))).view(1, 1, -1) # self.embedding(input).view(1, 1, -1)\n","        output = embedded\n","        output, hidden = self.lstm(output, hidden)\n","        return output, hidden\n","\n","    def initHidden(self):\n","        if self.number_of_layers==1:\n","            return (torch.zeros(1, 1, self.hidden_size, device=device), torch.zeros(1, 1, self.hidden_size, device=device))\n","        else:\n","            return (torch.zeros(2, 1, self.hidden_size, device=device), torch.zeros(2, 1, self.hidden_size, device=device))\n","\n","class AttnDecoderLSTM(nn.Module):\n","    def __init__(self, hidden_size, output_size, dropout_p=0.1, number_of_layers=1):\n","        super(AttnDecoderLSTM, self).__init__()\n","        self.hidden_size = hidden_size\n","        self.output_size = output_size\n","        \n","        self.dropout_p = dropout_p\n","        self.number_of_layers=number_of_layers\n","        \n","        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n","        self.tanh = nn.Tanh()\n","        \n","        self.Ua = nn.Linear(self.hidden_size, self.hidden_size)\n","        self.Wa = nn.Linear(self.hidden_size, self.hidden_size)\n","        \n","        #self.va = torch.randn(1, hidden_size).clone().detach().requires_grad_(True)# torch.tensor(torch.randn(1, hidden_size), requires_grad=True)#.cuda()\n","        self.va = nn.Parameter(torch.zeros(1, hidden_size)) #nn.Parameter(torch.rand(hidden_size))\n","        \n","        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n","        \n","        self.dropout = nn.Dropout(self.dropout_p)\n","        self.lstm = nn.LSTM(self.hidden_size, self.hidden_size, num_layers=number_of_layers)\n","        self.out = nn.Linear(self.hidden_size * 2, self.output_size)\n","        \n","    def forward(self, input, hidden, encoder_hiddens):\n","        embedded = (self.dropout(self.embedding(input))).view(1, 1, -1)\n","\n","        encoder_hiddens = encoder_hiddens.unsqueeze(1)\n","\n","        attn_weights = F.softmax(torch.inner(\n","            self.va, self.tanh(self.Ua(encoder_hiddens) + self.Wa(hidden[0]))), dim=1)\n","\n","        context = torch.sum(\n","            torch.mul(attn_weights, encoder_hiddens.squeeze()), dim=1)\n","\n","        output = torch.cat((embedded[0], context), 1)\n","        output = self.attn_combine(output).unsqueeze(0)\n","\n","        output = F.relu(output)\n","        output, hidden = self.lstm(output, hidden)\n","\n","        cat_output = torch.cat((context, output[0]), 1)\n","        output = F.log_softmax(self.out(cat_output), dim=1)\n","\n","        return output, hidden, attn_weights\n","    \n","    def initHidden(self):\n","        return torch.zeros(1, 1, self.hidden_size, device=device)\n","    \n","   \n","import time\n","import math\n","\n","def asMinutes(s):\n","    m = math.floor(s / 60)\n","    s -= m * 60\n","    return '%dm %ds' % (m, s)\n","\n","def timeSince(since, percent):\n","    now = time.time()\n","    s = now - since\n","    es = s / (percent)\n","    rs = es - s\n","    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n","\n","def showPlot(points, accuracy):\n","    plt.figure()\n","    fig, ax = plt.subplots()\n","    loc = ticker.MultipleLocator(base=0.2)\n","    ax.yaxis.set_major_locator(loc)\n","    plt.plot(points)\n","    plt.plot(accuracy)\n","    plt.show()\n","\n","def train2(input_tensor, target_tensor, encoder, decoder, \n","          encoder_optimizer, decoder_optimizer, criterion, seed,\n","          model):\n","  \n","    teacher_forcing_ratio=0.5\n","    torch.manual_seed(seed)\n","\n","    encoder_hidden = encoder.initHidden()\n","    encoder_optimizer.zero_grad()\n","    decoder_optimizer.zero_grad()\n","    \n","    input_length = input_tensor.size(0)\n","    target_length = target_tensor.size(0)\n","    \n","    encoder_hiddens = torch.zeros(input_length, encoder.hidden_size, device=device)\n","    \n","    loss = 0\n","    gold_pred = 0\n","    \n","    for ei in range(input_length):\n","        encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)#encoder_hidden\n","        if model==\"lstm\":\n","            encoder_hiddens[ei] = encoder_hidden[0][0, 0]\n","        elif model==\"gru\":\n","            encoder_hiddens[ei] = encoder_hidden[0, 0]\n","        \n","    decoder_input = torch.tensor([[SOS_token]], device=device)\n","    decoder_hidden = encoder_hidden\n","    \n","    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n","    \n","    if use_teacher_forcing:\n","        for di in range(target_length):\n","            decoder_output, decoder_hidden, decoder_attention = decoder(\n","                decoder_input, decoder_hidden, encoder_hiddens)\n","            topv, topi = decoder_output.topk(1)\n","            pred = topi.squeeze()\n","            \n","            if torch.equal(pred, target_tensor[di].squeeze()):\n","                gold_pred += 1\n","            \n","            loss += criterion(decoder_output, target_tensor[di])\n","            decoder_input = target_tensor[di]\n","            \n","    else:\n","        for di in range(target_length):\n","            decoder_output, decoder_hidden, decoder_attention = decoder(\n","                decoder_input, decoder_hidden, encoder_hiddens)\n","            topv, topi = decoder_output.topk(1)\n","            pred = topi.squeeze()\n","            decoder_input = topi.squeeze().detach()\n","            \n","            if torch.equal(pred, target_tensor[di].squeeze()):\n","                gold_pred += 1\n","            \n","            loss += criterion(decoder_output, target_tensor[di])\n","            if decoder_input.item() == EOS_token:\n","                target_length = di + 1\n","                break\n","\n","    loss.backward()\n","    \n","    torch.nn.utils.clip_grad_norm_(encoder.parameters(), max_norm=5.0)\n","    torch.nn.utils.clip_grad_norm_(decoder.parameters(), max_norm=5.0)\n","    encoder_optimizer.step()\n","    decoder_optimizer.step()\n","    \n","    return loss.item() / target_length, gold_pred, target_length\n","\n","def trainIters2(encoder, decoder, n_iters, data, seed, print_every=1000, plot_every=100,\n","               learning_rate=0.001, model=\"gru\"):\n","    start = time.time()\n","    \n","    plot_losses = []\n","    plot_accs = []\n","    print_loss_total = 0\n","    plot_loss_total = 0\n","    print_pred_total = 0\n","    print_label_total = 0\n","    plot_pred_total = 0\n","    plot_label_total = 0\n","    \n","    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n","    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n","    training_pairs = [tensorsFromPair(random.choice(data))\n","                      for i in range(n_iters)]\n","    criterion = nn.NLLLoss()\n","    \n","    for iter in range(1, n_iters + 1):\n","        training_pair = training_pairs[iter - 1]\n","        input_tensor = training_pair[0]\n","        target_tensor = training_pair[1]\n","        # target_length = target_tensor.size(0)\n","        \n","        loss, gold_pred, target_length = train2(input_tensor, target_tensor, encoder,\n","                     decoder, encoder_optimizer, decoder_optimizer, criterion, seed, model=model)\n","        print_label_total += target_length\n","        print_pred_total += gold_pred\n","        plot_label_total += target_length\n","        plot_pred_total += gold_pred\n","        print_loss_total += loss\n","        plot_loss_total += loss\n","        \n","        if iter % print_every == 0:\n","            print_acc_avg = print_pred_total / print_label_total\n","            print_loss_avg = print_loss_total / print_every\n","            print_pred_total = 0\n","            print_label_total = 0\n","            print_loss_total = 0\n","            print('%s (%d %d%%) loss: %.4f acc: %.4f' % (timeSince(start, iter / n_iters),\n","                                iter, iter / n_iters * 100, print_loss_avg, print_acc_avg))\n","            \n","        if iter % plot_every == 0:\n","            plot_acc_avg = plot_pred_total / plot_label_total\n","            plot_loss_avg = plot_loss_total / plot_every\n","            plot_losses.append(plot_loss_avg)\n","            plot_accs.append(plot_acc_avg)\n","            plot_loss_total = 0\n","            plot_pred_total = 0\n","            plot_label_total = 0\n","            \n","    showPlot(plot_losses, plot_accs)\n","    return encoder, decoder\n","\n","def evaluate(encoder, decoder, sentence):\n","    with torch.no_grad():\n","        input_tensor = tensorFromSentence(input_lang, sentence)\n","        input_length = input_tensor.size(0)\n","        encoder_hidden = encoder.initHidden()\n","\n","        for ei in range(input_length):\n","            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n","                                                     encoder_hidden)\n","\n","        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n","\n","        decoder_hidden = encoder_hidden\n","\n","        decoded_words = []\n","\n","        while(True):\n","            decoder_output, decoder_hidden = decoder(\n","                decoder_input, decoder_hidden)\n","            topv, topi = decoder_output.data.topk(1)\n","            if topi.item() == EOS_token:\n","                decoded_words.append('')\n","                break\n","            else:\n","                decoded_words.append(output_lang.index2word[topi.item()])\n","\n","            decoder_input = topi.squeeze().detach()\n","\n","        return decoded_words\n","    return sum/len(pairs)\n","\n","\n","def accuracy(encoder, decoder, pairs):\n","    sum = 0\n","    i = 0\n","    p = math.floor(len(pairs)/100)\n","    for pair in pairs:\n","        i+=1\n","        if (i % p == 0):\n","            print(\"%.2f\" % (i/len(pairs))) \n","        output_words = evaluate(encoder, decoder, pair[0])[0:-1]\n","        output_sentence = ' '.join(output_words)\n","        if output_sentence == pair[1]:\n","            sum +=1\n","    return sum/len(pairs)\n","\n","\n","\n","def evaluateRandomly(encoder, decoder, n=10):\n","    for i in range(n):\n","        pair = random.choice(pairs_test)\n","        print('Input', pair[0])\n","        print('Real:', pair[1])\n","        output_words = evaluate(encoder, decoder, pair[0])[0:-1]\n","        output_sentence = ' '.join(output_words)\n","        print('Pred:', output_sentence)\n","        print('')\n","        \n","def evaluate_attention(encoder, decoder, sentence):\n","    with torch.no_grad():\n","        input_tensor = tensorFromSentence(input_lang, sentence)\n","        input_length = input_tensor.size()[0]\n","        encoder_hidden = encoder.initHidden()\n","\n","        encoder_outputs = torch.zeros(input_length, encoder.hidden_size, device=device)\n","\n","        for ei in range(input_length):\n","            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n","                                                     encoder_hidden)\n","            encoder_outputs[ei] += encoder_output[0, 0]\n","\n","        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n","\n","        decoder_hidden = encoder_hidden\n","\n","        decoded_words = []\n","        decoder_attentions = torch.zeros(input_length, input_length)\n","\n","        di = 0\n","        while(True):\n","            decoder_output, decoder_hidden, decoder_attention = decoder(\n","                decoder_input, decoder_hidden, encoder_outputs)\n","            if(di < input_length):\n","                decoder_attentions[di] = decoder_attention.data.squeeze()\n","                di +=1\n","            topv, topi = decoder_output.data.topk(1)\n","            if topi.item() == EOS_token:\n","                decoded_words.append('')\n","                break\n","            else:\n","                decoded_words.append(output_lang.index2word[topi.item()])\n","\n","            decoder_input = topi.squeeze().detach()\n","\n","        return decoded_words, decoder_attentions[:di + 1]\n","\n","def accuracy_attention(encoder, decoder, pairs):\n","    sum = 0\n","    i = 0\n","    p = math.floor(len(pairs)/100)\n","    for pair in pairs:\n","        i+=1\n","        if (i % p == 0):\n","            print(\"%.2f\" % (i/len(pairs))) \n","        output_words, attention = evaluate_attention(encoder, decoder, pair[0])\n","        output_sentence = ' '.join(output_words[0:-1])\n","        if output_sentence == pair[1]:\n","            sum +=1\n","    return sum/len(pairs)\n","\n","def evaluateRandomly_attention(encoder, decoder, pairs, n=10):\n","    for i in range(n):\n","        pair = random.choice(pairs)\n","        print('Input', pair[0])\n","        print('Real:', pair[1])\n","        output_words, attention = evaluate_attention(encoder, decoder, pair[0])\n","        output_sentence = ' '.join(output_words[0:-1])\n","        print('Pred:', output_sentence)\n","        print('')\n","\n","\n","#taken from pytorch tutorial\n","def showAttention(input_sentence, output_words, attentions):\n","    # Set up figure with colorbar\n","    fig = plt.figure()\n","    ax = fig.add_subplot(111)\n","    cax = ax.matshow(attentions.numpy(), cmap='bone')\n","    fig.colorbar(cax)\n","\n","    # Set up axes\n","    ax.set_xticklabels([''] + input_sentence.split(' ') +\n","                       ['<EOS>'], rotation=90)\n","    ax.set_yticklabels([''] + output_words)\n","\n","    # Show label at every tick\n","    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n","    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n","\n","    plt.show()\n","\n","\n","def evaluateAndShowAttention(input_sentence, encoder, decoder):\n","    output_words, attentions = evaluate_attention(\n","        encoder, decoder, input_sentence)\n","    print('input =', input_sentence)\n","    print('output =', ' '.join(output_words))\n","    showAttention(input_sentence, output_words, attentions)\n"],"metadata":{"id":"GPcE8Emuh80p","executionInfo":{"status":"ok","timestamp":1674039741665,"user_tz":-60,"elapsed":328,"user":{"displayName":"Marie Mortensen","userId":"14481540874930151406"}}},"id":"GPcE8Emuh80p","execution_count":5,"outputs":[]},{"cell_type":"code","source":["prim_extra_dict = {\"Run\":[], \"Accuracy\":[], \"Seed\":[], \"N_Comp\":[]}\n","\n","amounts = [1,2,4,8,16,32]\n","rep = [1,2,3,4,5]\n","\n","for amount in amounts:\n","    for reps in rep:\n","              prim_extra_dict[\"N_Comp\"].append(amount)\n","              print(\"Comp amount is: \", amount)\n","\n","              # For every comp amount\n","              # Run a model 5 times and plot results\n","              input_lang, output_lang, pairs_comp = prepareData(f\"add_prim_split/with_additional_examples/tasks_train_addprim_complex_jump_num{amount}_rep{reps}\")\n","              input_lang_test, output_lang_test, pairs_test_comp = prepareData(f\"add_prim_split/with_additional_examples/tasks_test_addprim_complex_jump_num{amount}_rep{reps}\")\n","              \n","              hidden_size = 100\n","              input_size = input_lang.n_words\n","              output_size = output_lang.n_words\n","\n","              # Using LSTM\n","              encoder1lstm = EncoderLSTM(input_lang.n_words, hidden_size, dropout_prob=0.1, number_of_layers=1).to(device)\n","              decoder1lstm = AttnDecoderLSTM(hidden_size, output_size, dropout_p=0.1, number_of_layers=1).to(device)\n","              \n","              encoder1lstm, decoder1lstm = trainIters2(encoder1lstm, decoder1lstm, n_iters=10000, print_every=2000, data=pairs_comp, seed=42, model=\"lstm\")\n","              print(\"Accessing accuracies\")\n","              \n","              torch.save(encoder1lstm.state_dict(), f\"encoder{amount}{reps}.pt\")\n","              torch.save(decoder1lstm.state_dict(), f\"decoder{amount}{reps}.pt\")\n","\n","              accuracy_iter = accuracy_attention(encoder1lstm, decoder1lstm, pairs_test_comp)\n","\n","              prim_extra_dict[\"Accuracy\"].append(accuracy_iter)\n","\n"],"metadata":{"id":"8bLouUQ8hS5Q"},"id":"8bLouUQ8hS5Q","execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"6YRFiOH-k0dF"},"id":"6YRFiOH-k0dF","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.12"},"colab":{"provenance":[]},"accelerator":"GPU","gpuClass":"standard"},"nbformat":4,"nbformat_minor":5}